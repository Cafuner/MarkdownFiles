## 基于信息中心网络架构的音视频直播系统

这个项目是基于一种叫做Information Centric Network的网络，简称ICN。它是不同与传统的TCP/IP网络的一种面向未来的网络架构。在学术界它被认为是最有可能取代TCP/IP的网络架构。它与TCP/IP最核心的不同点就是对资源命名，而不是对主机命名。这种网络的的传输方式是依靠两种类型的的包，一个叫Interest，一个叫Data。主机向网络发送Interest包来请求资源，每个Interest携带一个可路由的资源名称，网络最终返回给主机一个Data包。这种架构具有网内缓存、天然支持广播、高安全性等特点。至于为什么有这些特点我先跳过，如果您感兴趣我可以展开讲。我的研究就是在这样的网络上设计和实现视频直播系统。

具体的实现分为音视频采集、传输和播放。

1. 音视频采集我是利用开源的ffmpeg的api来进行采集的，用开源的x264编码器对视频进行编码。
2. 音视频的传输的基本原理是把视频按照MTU进行分包，每个包都有序列号，客户端不断发送Interest请求视频包，服务器一边产生包一边响应Interest。在传输层我用的是经过修改适配ICN网路的RTP协议。RTP协议的视频和音频是分开传输的，所以我用两个socket分别传输两种数据，在客户端一个线程采用epoll来多路复用同时监听这两个socket的读事件。服务端整体上是一个生产者消费者模型。我用了两个线程和一个环形队列缓冲区。一个线程按照固定的速率去生成视频数据，放到缓冲区，另一个线程监听socket，从缓冲区拿数据响应客户发来的Interest。这两个线程相当于一个生产者一个消费者，所以他们用的生产者消费者的并发控制模型。有一点区别在于，我这里没有队列不满的条件变量，因为我的生产者会不断生产数据，如果满了就把旧数据覆盖。
3. 播放我用的是一个开源的视频播放器，VLC，它的代码是高度模块化的，我把其中的输入部分换成了我从ICN网络收到的数据包，从而实现了播放。



## ICN网络相比于TCP/IP网络有什么优势？

1. 最核心的是网内缓存。ICN网络的每个路由器都有数据缓存，如果它收到的Interest命中了缓存，那么就不用转发这个请求了，直接用缓存来响应请求即可。
2. 天然支持广播，极大的提高了广播的效率。在网络中每个路由器都是有状态的，如果它的多个网络结构收到了对同一种资源的请求，那么它就可以合并这些请求，只向服务器发出一份请求，等响应到达的时候给每个端口都发一份即可。这样就极大的减轻了上游的带宽负担。
3. 去中性化。ICN网络是直接对数据命名，所以不需要域名解析服务。另外，由于网内所有节点都可以缓存和发布数据，所以减少了对中心化服务器的依赖。
4. 安全性。由于ICN网络允许每个节点缓存数据，所以它必须要对数据的真实性做保障。也就说它的Data是服务器做过数字签名的，只要客户端能用服务器的公钥解码出正确的报文摘要，那么数据就是真实可信的。



## ICN网络有什么劣势吗？

1. 过渡成本。TCP/IP网络架构在工业界已经非常成熟了，如果要过渡到新的网络架构成本非常高。对此问题也有一些兼容现有架构的研究工作，比如类似IPv6的隧道模式等等。
2. 在小规模网络中，ICN的复杂机制可能会得不偿失。这是因为ICN中的路由器是有状态的，他需要维护历史转发的Interest包和缓存。因此在小规模网络中可能没有TCP/IP直接转发的性能更高。





## 应用层如何管理ICN网络

Interest包和Data包的包头都有一些字段，应用层在发包时可以配置这些字段。

例如，在Interest包头中如下字段：

1. InterestLifeTime：设置Interest在网络中存留的最大时间。
2. HopLimit：设置Interest在网络中被转发的最多次数。
3. CanBePrefix：Interest携带的资源名称是否可以被含有该前缀的Data响应。

在Data包中：

1. Timestamp：Data产生的时间戳。
2. Signature：数字签名信息。
3. Metainfo：Data包长度、生命周期等。





## ICN的组播比UDP组播有什么优势

1. ICN的组播是天然形成的，对应用层透明，没有多余的开销，只要多个客户端请求的是相同的数据就可以形成组播，所以严格来将主机请求的所有资源都经过了组播。而UDP的组播需要应用层参与，利用IGMP协议注册到指定的组播组，组播实现机制复杂且有额外的开销，而且只有自己什么加入的组播组里的资源才是组播，其他资源仍然是单播。
2. ICN的组播支持的范围更广。在ICN网络中的每个路由器都可以通过合并Interest和分发Data来实现组播，因此极端情况下对于某一种资源可能全网只有一个根节点，形成一个巨大的广播树。所以本质上ICN对组播的数量和组播成员的数量都没有限制。而UDP中要实现组播那么源主机和目的主机之间的所有路由器都必须支持IGMP协议。但目前在广域网级别上的路由器默认都禁止传播组播组，所以很难实现大范围的UDP组播。



## 面向对象编程的四大特征

1. **抽象**

    抽象是将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象两方面。抽象只关注对象的哪些属性和行为，并不关注这此行为的细节是什么。

    - 作用：隐藏具体实现，使用者只需关心功能，无需关心实现。
    - 意义：提高代码的扩展性、维护性；降低复杂度，减少细节负担。

2. **封装**

    装就是将抽象得到的数据和行为相结合，形成一个有机的整体，也就是将数据与操作数据的源代码进行有机的结合，形成类，其中数据和函数都是类的成员。

    封装的好处：

    + 良好的封装能够减少耦合，类内部的结构的修改不影响外部代码的使用。
    + 将类的使用者和设计者分开，使用者要访问该类的代码和数据，必须通过严格的接口控制，增强了模块的安全性。
    + 将现实世界的物体抽象成为类，有利于代码重用。

3. **继承**

    类的继承指的是从已有类产生新类的过程。一般来说有如下三种继承方式：

    1. 单一继承：继承一个父类，这种继承称为单一继承，这也是我们用的做多的继承方式。
    2. 多重继承：一个派生类继承多个基类，类与类之间要用逗号隔开，类名之前要有继承权限，假使两个或两个基类都有某变量或函数，在子类中调用时需要加**类名限定符**如obj.classA::i = 1；
    3. 菱形继承：多重继承掺杂隔代继承1-n-1模式，此时需要用到虚继承，例如 B，C虚拟继承于A，D再多重继承B，C，否则会出错。

    继承的好处：

    + 提高了代码的复用性
    + 提高了代码的可维护性
    + 建立了类与类之间的关系，继承是多态的前提。

    继承的缺点

    + 在一定程度上，造成类与类之间的强关联，即所谓的高耦合，父类功能的改变对子类也会造成影响。

4. **多态**

    可以简单概括为“一个接口，多种方法”，即用的是同一个接口，但是效果各不相同，多态有两种形式的多态，一种是静态多态，一种是动态多态。

    **静态多态**。也称为编译期间的多态，编译器在编译期间完成的，编译器根据函数实参的类型(可能会进行隐式类型转换)，可推断出要调用那个函数，如果有对应的函数就调用该函数，否则出现编译错误。 静态多态有两种实现方式：1.函数重载：包括普通函数的重载和成员函数的重载。 2.函数模板的使用。

    **动态多态**。即运行时的多态，在程序执行期间(非编译期)判断所引用对象的实际类型，根据其实际类型调用相应的方法。对于相关的对象类型，确定它们之间的一个共同功能集，然后在基类中，把这些共同的功能声明为多个公共的虚函数接口。各个子类重写这些虚函数，以完成具体的功能。具体实现就是c++的虚函数。

    多态是以封装和继承为基础实现的性质 ，多态是方法的多态，不是属性的多态（多态与属性无关）。多态的存在有三个必要条件：继承，方法重写，父类引用指向子类对象。父类引用指向子类对象后，用该父类引用调用子类重写的方法，此时多态就产生了。



## 面向过程和面向对象编程的区别

面向过程就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了。面向过程的性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、嵌入式开发、 Linux/Unix等一般采用面向过程开发，性能是最重要的因素。



面向对象是把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为。面向对象易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统 更加灵活、更加易于维护。



## 结构体(struct)和共同体(union)的区别

结构体struct：把不同类型的数据组合成一个整体。struct里每个成员都有自己独立的地址。sizeof(struct)是内存对齐后所有成员长度的加和。（引申出内存对齐的问题）

共同体union：各成员共享一段内存空间, 一个union变量的长度等于各成员中最长的长度，以达到节省空间的目的。所谓的共享不是指把多个成员同时装入一个union变量内, 而是指该union变量可被赋予任一成员值,但每次只能赋一种值, 赋入新值则冲去旧值。 



## 内存对齐

32位系统cpu一次寻址4个字节，64位系统一次寻址8个字节

以64位系统为列：CPU一次寻址都是从地址为8的倍数的地址开始寻址，如果存储的数据都是内存对齐的，即每一个数据的首地址也都是存放在以8为倍数的地址中，那么CPU一次寻址就可以读取整个数据。

如果没有内存对齐，数据都是一个接着一个存储的。那么为了访问未对齐的数据的内存，CPU处理器一次读取的内存数据(8字节)可能包含两个数据的存储数据，而导致数据读取不完整，需要作两次内存访问；而对齐的内存访问仅需要一次访问。


如果一个变量的内存地址正好位于它长度的整数倍，他就被称做**自然对齐**。数据结构应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。

每个特定平台上的编译器都有自己的默认“对齐系数”（也叫对齐模数）。32位系统，gcc中默认#pragma pack(4)，可以通过预编译命令#pragma pack(n)，n = 1,2,4,8,16来改变这一系数。

**有效对齐值**：是给定值#pragma pack(n)和结构体中最长数据类型长度中较小的那个。有效对齐值也叫对齐单位。

然后明确内存对齐的两个规则：

1.结构体第一个成员的偏移量（offset）为0，以后每个成员相对于结构体首地址的 offset 都是该成员大小与有效对齐值中较小那个的整数倍，如有需要编译器会在成员之间加上填充字节。

2.结构体的总大小为 有效对齐值 的整数倍，如有需要编译器会在最末一个成员之后加上填充字节。



## C++的多态

分为静态多态和动态多态。

### 静态多态

又称为编译时多态。在编译器就能够确定函数的地址。实现方式例如函数重载、函数模版。

### 动态多态

又称为运行时多态。在运行时根据具体的对象才能确定函数的地址。实现方式是派生类重写基类的虚函数，用基类的指针引用派生类对象，调用虚函数时会调用派生类重写后的函数。

虚函数的实现原理：

1. 每个含有虚函数的类的对象都有一个虚函数表指针（虚函数表存储在只读数据段，虚函数本身和普通函数一样存储在代码段）。派生类的虚函数表中会有超类的虚函数表的副本。
2. 当创建子类对象时，编译器对虚函数表指针的初始化过程：
    1. 对象在创建时，由编译器对 vptr 进行初始化，虚函数表指针属于类对象，存储在堆或者栈上
    2. 子类的构造会先调用父类的构造函数，这个时候 vptr 会先指向父类的虚函数表
    3. 子类构造的时候，vptr 会再指向子类的虚函数表
    4. 对象的创建完成后，vptr 最终的指向才确定
3. 单继承的派生类的虚函数表的形成过程：
    1. 先拷贝基类的虚表 
    2. 如果派生类重写了基类的虚函数，则修改同位置的基类虚函数地址，指向新的函数
    3. 跟上派生类新定义的虚函数
4. 多继承的派生类的结构是，有一张虚函数表，但是是n个基类的虚函数表拼接而成，类对象中还有n个虚函数表指针，指向了虚函数表中的不同位置。此外，派生类自己的新添加的虚函数会被放在虚函数表中第一个基类的函数的后面。

<img src="/Users/yv_zhanghao/Documents/MarkdownFiles/C++/1.png">



纯虚函数：

纯虚函数是基类不给出默认实现的虚函数，申明了纯虚函数的类称为抽象类（注意，c++中没有abstract关键字）。抽象类无法实例化，继承抽象类的派生类要么也为抽象类，要么实现所有的纯虚函数，则可以进行实例化。

另外注意：

1. 构造函数不可以是虚函数，虚函数表和虚函数表指针的建立在构造函数之后。另外，我们也没有需求让构造函数成为虚函数，因为我们在创建对象时调用的是派生类的构造方法，构造好之后才用基类指针去引用。
2. 析构函数建议申明为虚函数，实际上是必须为虚函数。如果对象是在栈上，那么对象会随着函数栈的销毁而释放，但是如果在堆上，释放一个基类指针时，如果析构函数不是虚函数，那么就不会调用派生类的析构函数，从而导致派生类的成员无法被释放，造成内存泄漏。



## const 和 constexpr的区别

const表示只读常量。在c11以前，const有双重语义，一方面表示只读，一方面如果用常量表达式来初始化const变量，那么编译器会认为该变量是常量。所以，对于用常量表达式初始化的const变量，可以用来初始化数组长度等，因为它的值在编译期就可以确定，而且不会改变。

在c11后，引入了constexpr，将const的双重语义分离，const只保留只读的含义，而constexpr表示常量的含义。



## C++11的新特性

### 变量和基本类型

1. long long 长整数
2. nullptr 空指针常量
3. 列表初始化。用花括号来初始化变量得到了全面应用，这种初始化的形式被成为**列表初始化**。无论是类的变量，数组，stl的容器，类的构造，都统一使用{}，以后只要是初始化就首先考虑{}的初始化就OK了。
4. constexpr 编译器常量
5. using 起别名。 using可以用于定义模板别名，而typedef不能。
6. auto和decltype。auto通过变量的初始值来推断变量的类型，所以会计算出变量的初始值。auto会忽略掉顶层const, 保留底层const. 而decltype 从表达式的类型推断出要定义的变量的类型，不进行计算。不论是顶层const还是底层const, decltype都会保留。另外，如果decltype内的表达式被括号包裹，那么会返回引用类型。

### 字符串、向量和数组

1. 范围for语句
2. vector对象的vector，两个尖括号之间可以不加空格了
3. 容器的cbegin和cend函数，返回const迭代器

### 函数和表达式

1. return {} 这个用法的含义是返回一个用列表初始化构造的函数返回值的类型对象。例如

```c++
vector<int> twoSum(vector<int>& nums, int target) {
	return {1, 2, 3};    //直接构造好vector<int>并将这个对象返回
}
```

2. 非成员版本的swap函数。

3. lambda表达式。**[capture] (parameters) -> return value { body }**,只有 [capture] 捕获列表和 { body } 函数体是必选的，其他可选。lambda表达式的捕捉列表：

    [] 不捕获任何变量,这种情况下lambda表达式内部不能访问外部的变量。
    [&] 以引用方式捕获所有变量
    [=] 用值的方式捕获所有变量（可能被编译器优化为const &)
    [=, &foo] 以引用捕获变量foo, 但其余变量都靠值捕获
    [&, foo] 以值捕获foo, 但其余变量都靠引用捕获
    [bar] 以值方式捕获bar; 不捕获其它变量
    [this] 捕获所在类的this指针 （Qt中使用很多，如此lambda可以通过this访问界面控件的数据）

4. 右值引用。分为纯右值引用和消亡值引用。

    1. 纯右值例如除了字符串以外的字面量，nullptr，true，false等。
    2. 消亡值是一些临时对象。




### 类

1. 委托构造函数。在c++11以前，构造函数不能调用另一个构造函数，因为它实际上是会创建一个新的匿名对象进行初始化，而不是初始化当前对象。c++11提出了委托构造函数机制，使用方法类似类的成员变量初始化。但是要注意，使用了委托构造函数后，就不能再使用成员变量初始化。
1. final 关键字。作用于函数则不能被重写，作用于类则不能被继承。
1. override，显式地声明对基类虚函数的重写。



### 标准库

C++的map,multimap,set,multiset使用红黑树实现，插入和查询都是O(logn)的复杂度；但C++11为四种unordered模板类提供底层哈希实现以达到O(1)的复杂度：

1. unordered_set

2. unordered_multiset
3. unordered_map
4. unordered_multimap

并发支持：

1. mutex

2. recursive_mutex

3. timed_mutex

4. timed_recuresive_mutex

5. condition_variable

6. lock_guard<Mutex>，只支持自动的加锁和释放

7. unique_lock<Mutex>，支持自动手动加锁和释放

8. c++17引入了 shared_mutex，支持互斥锁和共享锁，通常使用unique_lock进行互斥锁，使用shared_lock进行共享锁。

    shared_lock是read lock。搭配std::shared_mutex使用，被锁后仍允许其他线程执行同样被shared_lock的代码。

    lock_guard和unique_lock是write lock。被锁后不允许其他线程执行被shared_lock或unique_lock的代码。

RAII思想实现的智能指针。



## RAII

RAll (Resource Acquisition ls Initialization）是由c++之父Bjarne Stroustrup提出的，中文翻译为资源获取即初始化，使用局部对象来管理资源的技术称为资源获取即初始化；这里的资源主要是指操作系统中有限的东西如内存(heap)、网络套接字，互斥量，文件句柄等等，局部对象是指存储在栈的对象，它的生命周期是由操作系统来管理的，无需人工介入。

RAII方式使用资源的过程：

1. 创建对象的同时获取并初始化资源
2. 使用资源
3. 析构对象的同时销毁资源

由于在栈上的对象会自动析构，所以可以自动释放资源。

举例，lock_guard和unique_lock都是RAII风格的互斥锁，智能指针。



## 智能指针

智能指针本质是一个封装了一个原始C++指针的类模板，为了确保动态内存的安全性而产生的。实现原理的核心思想就是RAII，通过创建一个对象存储需要的资源，然后依靠对象的析构函数来释放资源。只不过，智能指针还有引用计数功能，使得包装类的析构函数可以正确的释放资源。

智能指针是封装原始指针的类，用于解决悬空(dangling)指针或多次删除被指向对象，以及资源泄露问题，通常用来确保指针的寿命和其指向对象的寿命一致。

原始指针的缺点有：

1. 需要**手动管理内存**
2. 容易发生**内存泄露**（忘记释放、出现异常等）
3. 释放之后**产生野指针**

C++11提供了四种智能指针：auto_ptr(C++17已移除)； unique_ptr； shared_ptr;  weak_ptr；

因为 auto_ptr 已经在 C++ 17 中移除，这里不再研究该类型。又因为weak_ptr是shared_ptr的弱引用，所以，主要的智能指针分为两个unique_ptr和shared_ptr。

### unique_ptr

std::unique_ptr 是通过指针占有并管理另一对象，并在 unique_ptr 离开作用域时释放该对象的智能指针。在下列两者之一发生时用关联的删除器释放对象：

+ 销毁了管理的 unique_ptr 对象
+ 通过 operator= 或 reset() 赋值另一指针给管理的 unique_ptr 对象。

可以使用构造函数或make_unique来构造unique_ptr。

unique_ptr不允许被复制，但是可以通过函数返回给其他的unique_ptr，还可以通过std::move（）转移给其他的unique_ptr。还是一个unique_ptr独占一个地址。unique_ptr满足可移动构造 (MoveConstructible) 和可移动赋值 (MoveAssignable) 的要求，但不满足可复制构造 (CopyConstructible) 或可复制赋值 (CopyAssignable) 的要求。 因此不可以使用 = 操作和拷贝构造函数，仅能使用移动操作。



### shared_ptr

std::shared_ptr 是通过指针保持对象共享所有权的智能指针。多个 shared_ptr 对象可占有同一对象。下列情况之一出现时销毁对象并解分配其内存：

+ 最后剩下的占有对象的 shared_ptr 被销毁；
+ 最后剩下的占有对象的 shared_ptr 被通过 operator= 或 reset() 赋值为另一指针。

有两种方式创建 shared_ptr。一种是调用构造函数，将已经创建的指针作为初始化参数。另一种是使用make_shared宏来加速创建的过程。make_shared会负责创建目标对象。

```c++
void main( )
{
 shared_ptr<int> sptr1( new int );
 shared_ptr<int> sptr2 = make_shared<int>(100);
}
```

也可以使用拷贝的方式初始化共享智能指针，这两个对象会同时管理同一块内存，堆内存对应的引用计数也会增加。

如果使用移动构造的方式初始化智能指针对象，只是转让了内存的所有权，管理内存的对象不会增加，因此内存引用技术不会增加。

shared_ptr默认调用delete释放关联的资源。如果用户采用一个不一样的析构策略时，他可以自由指定构造这个shared_ptr的策略。例如一个lamda表达式，来指定一个通用的释放步骤。

```c++
void main( )
{
 shared_ptr<Test> sptr1( new Test[5],
        [ ](Test* p) { delete[ ] p; } );
}
```



### weak_ptr

weak_ptr的引入是为了解决shared_ptr的循环引用问题。在shared_ptr的使用过程中，当强引用计数为0是，就会释放所指向的堆内存。那么问题来了，如果和死锁一样，当两个shared_ptr互相引用，那么它们就永远无法被释放了。

weak_ptr 的出现就是**为了解决shared_ptr的循环引用的问题的**。例如，**将两个循环引用的类中的一个成员变量改为weak_ptr对象**.

一个强引用当被引用的对象活着的话，这个引用也存在（就是说，当至少有一个强引用，那么这个对象就不能被释放）。share_ptr就是强引用。相对而言，弱引用当引用的对象活着的时候不一定存在。仅仅是当它存在的时候的一个引用。弱引用并不修改该对象的引用计数，这意味这弱引用它并不对对象的内存进行管理，在功能上类似于普通指针，然而一个比较大的区别是，弱引用能检测到所管理的对象是否已经被释放，从而避免访问非法内存。

弱引用智能指针 std::weak_ptr 可以看做是 shared_ptr 的助手，它不管理 shared_ptr 内部的指针。std::weak_ptr 没有重载操作符 * 和->，因为它不共享指针，不能操作资源，所以它的构造不会增加引用计数，析构也不会减少引用计数，它的主要作用就是作为一个旁观者监视 shared_ptr 中管理的资源是否存在。

通过调用 std::weak_ptr 类提供的 use_count() 方法可以获得当前所观测资源的引用计数。

通过调用 std::weak_ptr 类提供的 expired() 方法来判断观测的资源是否已经被释放。

通过调用 std::weak_ptr 类提供的 lock() 方法来获取管理所监测资源的 shared_ptr 对象。

通过调用 std::weak_ptr 类提供的 reset() 方法来清空对象，使其不监测任何资源。





## 匿名函数的本质是什么？他的优点是什么？

匿名函数本质上是一个对象，在其定义的过程中会创建出一个栈对象，内部通过重载()符号实现函数调用的外表。

优点：使用匿名函数，可以免去函数的声明和定义。这样匿名函数仅在调用函数的时候才会创建函数对象，而调用结束后立即释放，所以匿名函数比非匿名函数更节省空间。



## 为什么C++11引入了右值引用

主要有两个作用：

1. 支持移动语义。通过右值引用，可以引用临时变量等一些消亡值，代替复制构造函数的大规模拷贝操作，直接讲消亡值内部的资源指针和目标交换，实现移动大对象。
2. 支持完美转发。在函数模板中，可以将 自己的参数“完美”地转发给其它函数。所谓完美，即 不仅能准确地转发参数的值，还能保证被转发参数的左、右值属性不变。 C++11标准引入了右值引用和移动语义，所以，能否实现完美转发，决定了该参数在传递过程使用的是拷贝语义(调用拷贝构造函数)还是移动语义 (调用移动构造函数)。如果模板中 (包括类模板和函数模板)函数的参数书写成为T&& 参数名 那么，函数既可以接受左值引用，又可以接受右值引用。 提供了模板函数std::forward<T>(参数)，用于转发参数如果参数是一个右值，转发之后仍是右值引用;如果 参数是一个左值，转发之后仍是左值引用。





## 左值引用和指针的区别？

**是否初始化**：指针可以不用初始化，引用必须初始化

**性质不同**：指针是一个变量，引用是对被引用的对象取一个别名

**占用内存单元不同**：指针有自己的空间地址，引用和被引用对象占同一个空间。





## malloc的内存分配的方式，有什么缺点？

malloc并不是系统调用，而是C库中的函数，用于动态内存分配，在使用malloc分配内存的时候会有两种方式向操作系统申请堆内存

方式1：当用户分配的内存小于128KB时通过brk()系统调用从堆分配内存，实现方式：将堆顶指针向高地址移动，获取内存空间，如果使用free释放空间，并不会将内存归还给操作系统，而是会缓存在malloc的内存池中，待下次使用

方式2：当用户分配的内存大于128KB时通过mmap()系统调用在文件映射区域分配内存，实现方式为：使用私有匿名映射的方式，在文件映射区分配一块内存，也就是从文件映射区拿了一块内存，free释放内存的时候，会把内存归还给操作系统，内存得到真正释放

缺点：容易造成内存泄漏和过多的内存碎片，影响系统正常运行，还得注意判断内存是否分配成功，而且内存释放后（使用free函数之后指针变量p本身保存的地址并没有改变），需要将p的赋值为NULL拴住野指针。



## 为什么不全部使用mmap来分配内存？

因为向操作系统申请内存的时候，是要通过系统调用的，执行系统调用要进入内核态，然后再回到用户态，状态的切换会耗费不少时间，所以申请内存的操作应该避免频繁的系统调用，如果都使用mmap来分配内存，等于每次都要执行系统调用。另外，因为mmap分配的内存每次释放的时候都会归还给操作系统，于是每次mmap分配的虚拟地址都是缺页状态，然后在第一次访问该虚拟地址的时候就会触发缺页中断。

也就是说，**频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大**。

## 为什么不全部都用brk

如果全部使用brk申请内存那么随着程序频繁的调用malloc和free，尤其是小块内存，堆内将产生越来越多的不可用的内存碎片。





## free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？

malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节，这个多出来的 16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。





## define和const的区别是什么？

编译阶段：define是在编译预处理阶段进行简单的文本替换，const是在编译阶段确定其值

安全性：define定义的宏常量没有数据类型，只是进行简单的替换，不会进行类型安全检查；const定义的常量是有类型的，是要进行类型判断的

内存占用：define定义的宏常量，在程序中使用多少次就会进行多少次替换，内存中有多个备份，占用的是代码段的内存；const定义常量占用静态存储区域的空间，程序运行过程中只有一份





## 程序运行的步骤是什么

预编译：将头文件编译，进行宏替换，输出.i文件

编译：将其转化为汇编语言文件，主要做词法分析，语义分析以及检查错误，检查无误后将代码翻译成汇编语言，生成.s文件

汇编：汇编器将汇编语言文件翻译成机器语言，生成.o文件

链接：将目标文件和库链接到一起，生成可执行文件.exe

加载：操作系统将可执行文件加载到内存中，准备执行。

运行：程序开始执行。控制流按照程序的逻辑执行指令，操作系统调度进程执行，程序可能与用户交互，处理输入和输出等。



## struct和class有什么区别

struct的默认继承方式和访问权限是public，而class默认是private。c++保留struct是为了和c兼容。





## 类的生命周期

类从被加载到内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载七个阶段。其中验证，准备，解析三个部分统称为连接

全局对象在main开始前被创建，main退出后被销毁。

静态对象在第一次进行作用域时被创建，在main退出后被销毁。

局部对象在进入作用域时被创建，在退出作用域时被销毁。

New创建的对象直到内存被释放的时候都存在。




## ++i是左值还是右值，++i和i++哪个效率更高？

1. **`++i` 和 `i++` 是左值还是右值？**
    - `++i` 是左值，因为它表示一个具体的变量，可以出现在赋值语句的左边。
    - `i++` 是右值，因为这需要生成一个临时变量用于返回，i的值已经被递增。
2. **`++i` 和 `i++` 哪个效率更高？**
    - 在大多数情况下，`++i` 的效率更高。这是因为 `++i` 执行递增操作并返回递增后的值，而 `i++` 需要返回递增之前的值，因此需要使用一个临时变量保存原始值。编译器优化可能会减轻这种差异，但通常建议在没有特殊需求时使用 `++i`。

​          

## 全局变量和静态变量的初始化总结

### 1 全局变量

static initialization:

静态初始化，是针对于那些简单的、c++内部定义的数据结构，如int，double，bool及数组结构的初始化，又可分为zero和const两种方式。对于zero初始化，也就是我们没指定初值，编译器分配0值给它，编译时编译器将其分配在.bss段，不占用rom空间；而const初始化，也就是我们指定了初值，编译器将其分配在.data段，占用rom空间。

dynamic initialization:

这种初始化针对的是需要调用构造函数才能完成的初始化。这种初始化会在main函数执行前，在运行时由运行时库调用相应的代码进行初始化。

另外，静态初始化**先于**动态初始化。因为静态初始化发生在编译时期，直接写进.bss段和.data段，在程序执行时直接加载；而动态初始化则是在运行时期，由运行时库调用相应构造函数进行初始化，同样要写进.bss段或.data段。

### 2.类的静态成员变量

const的静态成员可以直接在类内进行初始化，而非const的静态成员需要在类外声明以初始化，对于后一种情况，我们一般选择在类的实现文件中初始化。至此，具体的初始化方式和上面说的是一致的，可在编译期间初始化，也可在运行期间初始化。

另外，在c++11后，类的非静态成员变量可以在类内进行初始化，但是在构造函数执行时进行初始化的，且构造函数会覆盖类内的初始化。



## shared_ptr线程安全吗？

智能指针中的引用计数是线程安全的，但是智能指针所指向的对象的线程安全问题，智能指针没有做任何保障线程不安全。也就是说它所管理的资源可以线程安全的释放，只保证线程安全的管理资源的生命期，不保证其资源可以线程安全地被访问。



## move底层是怎么实现的？

Move的功能是将一个左值引用强制转化为右值引用，继而可以通过右值引用使用该值，以用于移动语义，从实现原理上讲基本等同一个强制类型转换。

优点：可以将左值变成右值而避免拷贝构造，将对象的状态所有权从一个对象转移到另一个对象，只是转移，没有内存搬迁或者内存拷贝。



## 完美转发的原理是什么？

完美转发是指函数模板可以将自己的参数完美的转发给内部调用的其他函数，完美是指不仅能够准确的转发参数的值，还能保证被转发参数的左、右值属性不变，使用引用折叠的规则和forward函数进行类型转换，将传递进来的左值以左值传递出来，将传递进来的右值以右值的方式传出。

引用折叠就是说当多个引用嵌套的时候，如果有一个左值引用，则结果为左值引用，如果全部为右值引用，则结果为右值引用。



## 空类默认有哪些函数？

空类在C++中指的是没有任何成员变量、成员函数的类。即使是空类，它也默认拥有以下几个函数：

1. 默认构造函数（也称为无参构造函数）
2. 拷贝构造函数
3. 移动构造函数
4. 拷贝赋值运算符(取址运算符)
5. 移动赋值运算符(const 取址运算符)
6. 析构函数



## explicit用在哪里？有什么作用？

`explicit` 是 C++ 中的一个关键字，通常用于声明构造函数，防止隐式类型转换。它可以用在类的构造函数声明前，用于标识只接受显式调用的构造函数。`explicit` 关键字的作用是禁止编译器使用隐式类型转换将参数类型转换为类类型。





## new和malloc有什么区别

<img src="/Users/yv_zhanghao/Documents/MarkdownFiles/C++/2.jpg">



## 自由存储区和堆有什么区别

表面上似乎明显的区别在于：malloc在堆上分配的内存块，使用free释放内存，而new所申请的内存则是在自由存储区上，使用delete来释放。但是，二者又有密切的联系：

1. 一方面，很多new都是用malloc来实现的，这种情况下，堆就是自由存储区的一部分。
2. 另一方面，c++允许运算符重载，所以程序员可以重载new运算符，改用其他内存实现自由存储区，例如全局变量做的对象池，那么此时全局变量位于的静态存储区就是自由存储区的一部分了。



## 迭代器和指针的区别

迭代器不是指针，是一个模板类，通过重载了指针的一些操作符模拟了指针的一些功能，迭代器返回的是对象引用而不是对象的值。

指针能够指向函数而迭代器不行迭代器只能指向容器的元素。





## vector的push_back和emplace_back有什么区别

|                              | push_back        | emplace_back     |
| :--------------------------: | :--------------- | ---------------- |
|       是否支持右值引用       | 支持             | 支持             |
|    是否一定会发生拷贝构造    | 一定             | 不一定           |
| 是够支持直接传入多个构造参数 | 支持一个构造参数 | 支持多个构造参数 |
|       是够支持原地构造       | 不支持           | 支持             |

本质上，push_back和empace_back都支持复制构造和移动构造，所以如果我们要把一个已经创建好的对象添加到vector末尾，那么使用二者都可以，他们都会根据传入的是左值引用还是右值引用而选择拷贝构造函数或移动构造函数。

不同点在于，push_back只支持元素类型的参数，而emplace_back可以传入元素的构造器所需要的参数，emplace_back内部可以原地调用构造函数进行构造。这得益于c++11引入的右值引用和完美转发。

另外，由于存在隐式类型转换，所以push_back如果传入一个单参数构造函数的参数，编译器可以调用对应的构造函数将这个参数转换为对象。当然，如果单参数构造函数被申明为explicit则不可以进行隐式类型转换。



## vector扩容，resize和reserve的区别

首先，容器有size和capacity两个成员变量。size指的是容器含有的元素个数，capacity指的是容器的内存空间最多能够存储的元素个数。

因此，resize修改的是size，resize可能会销毁多余的元素，也可能会使用默认构造函数构造新的元素。当然，如果resize的目标值大于当前capacity，则会引起内存的重新分配。

reserve是预留，所以它修改的是capacity，但reserve的原则是只增不减，如果capacity已经足够大，那么reserve就直接返回。



## vector扩容为了避免重复扩容做了哪些机制？

当vector内存不够时本身内存会以1.5或者2倍的增长，以减少扩容次数。

1.5倍扩容对内存复用有优势，因为多次扩容后，前面释放的内存可能足够下一次分配。但是2倍扩容的条件下，之前释放的内存总和永远不能达到下一次扩容的需要。



## 哈希碰撞的处理方法

开放定址法：当遇到哈希冲突时，去寻找一个新的空闲的哈希地址。

再哈希法：同时构造多个哈希函数，等发生哈希冲突时就使用其他哈希函数知道不发生冲突为止，虽然不易发生聚集，但是增加了计算时间

链地址法：将所有的哈希地址相同的记录都链接在同一链表中

建立公共溢出区：将哈希表分为基本表和溢出表，将发生冲突的都存放在溢出表中





## unordered_map的扩容过程

当unordered_map中的元素数量达到桶的负载因子（0.75）时，会重新分配桶的数量（通常会按照原有桶的数量*2的方式进行扩容，但是具体的增长策略也可以通过修改容器中的max_load_factor成员变量来进行调整），并将所有的元素重新哈希到新的桶中。

负载因子 = 总键值对 / 桶数



## 构造函数是否能声明为虚函数？为什么？

构造函数不能为虚函数，虚函数的调用是通过虚函数表来查找的，而虚函数表由类的实例化对象的vptr指针指向，该指针存放在对象的内部空间之中，需要调用构造函数完成初始化，所以只有构造函数完成后，对象才可以调用虚函数表中的函数。构造函数自身自然不能是虚函数。



## 类中static函数是否能声明为虚函数？

不能。

从语义上来讲，static函数是属于类的，本来就是不可继承重写的，而虚函数的目的是实现多态，需要子类重写父类的虚函数，这与static的理念是冲突的。

从实现上来讲，调用虚函数需要通过this指针，找到对象的虚函数表指针，再找到虚函数表中虚函数的地址，实现调用。但是static函数是没有this指针的，所以虚函数表中不可能放static函数。



## 哪些函数不能被声明为虚函数？

1. 构造函数
2. 内联函数（内联函数有实体，在编译时展开，没有this指针）
3. 静态成员函数
4. 友元函数（C++不支持友元函数的继承，不能继承的函数指定不是虚函数）
5. 非类成员函数





## 什么是虚继承和虚基类

虚继承的引入是为了解决在多继承场景下的菱形继承问题。如果不引入该机制，在派生类中，就会存在多个间接基类，出现名称冲突、数据冗余等问题。

虚继承的目的是让某个类做出声明，承诺愿意共享它的基类。其中，这个被共享的基类就称为虚基类（Virtual Base Class）。在这种机制下，不论虚基类在继承体系中出现了多少次，在派生类中都只包含一份虚基类的成员。

虚继承的实现方式是，虚基类对象不存储在派生类中，而是存储在一个虚表中，并且给派生类一个虚表指针。当派生类要访问虚基类的成员变量时，就通过虚表去访问。这样一来，如果多个基类继承了同一个虚基类，那么派生类中将只有一份虚基类。



## 动态链接和静态链接的区别，动态链接的原理是什么？

区别：他们的最大区别就是在于链接的时机不同，静态链接是在形成可执行程序前，而动态链接的进行则是程序执行时。

静态库：就是将库中的代码包含到自己的程序之中，每个程序链接静态库后，都会包含一份独立的代码，当程序运行起来时，所有这些重复的代码都需要占用独立的存储空间，显然很浪费计算机资源。

动态库：不会将代码直接复制到自己程序中，只会留下调用接口，程序运行时再去将动态库加载到内存中，所有程序只会共享这一份动态库，因此动态库也被称为共享库。由于动态共享库会被映射到多个进程的虚拟地址空间，所以必须使用地址无关代码技术。

动态链接原理：是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件



## C++中怎么编译C语言代码？

使用extern“C”让C++代码按照C语言的方式去编译。例如在c++中调用ffmpeg的api。



## 设计一个类，使其只能在堆上创建

- 将类的构造函数私有，拷贝构造声明成私有。防止别人调用拷贝在栈上生成对象。
- 提供一个静态的成员函数，在该静态成员函数中完成堆对象的创建



## 设计一个类，使其只能在栈上创建

- 将类的构造函数私有。防止在堆上创建对象
- 提供一个静态的成员函数，在该静态成员函数中完成栈对象的创建



## 说一下内联函数及其优缺点

内联函数是在编译期将函数体内嵌到程序之中，以此来节省函数调用的开销。

**优点：**是节省了函数调用的开销，让程序运行更加快速。

**缺点：**是如果函数体过长，频繁使用内联函数会导致代码编译膨胀问题。不能递归执行





## 详细说一说fcntl的作用

作用：用于控制打开的文件描述符的一些属性和行为。

有五个功能：

1.复制一个现有的描述符(cmd=F_DUPFD)

2.获得/设置文件描述符标记（cmd=F_GETFD或F_SETFD）

3.获取/设置文件状态标记（cmd=F_GETFL或F_SETFL）

4.获取设置异步IO所有权（cmd=F_GETOWN或F_SETFL）

5.获取设置记录锁（cmd=F_GETLK或F_SET）





## 讲一讲迭代器失效及其解决方法

### 序列式容器迭代器失效

当当前元素的迭代器被删除后，后面所有元素的迭代器都会失效，他们都是一块连续存储的空间，所以当使用erase函数操作时，其后的每一个元素都会向前移动一个位置，此时可以使用erase函数操作可以返回下一个有效的迭代器。

### Vector迭代器失效问题总结

1.当执行了erase方法时，指向删除节点的迭代器全部失效，指向删除节点之后的全部迭代器也失效。

2.当进行push_back方法时，end操作返回的迭代器肯定失效。

3.当插入一个元素后，capacity返回值与没有插入元素之前相比有改变，则需要重新加载整个容器，此时first和end操作返回的迭代器失效。

4.当插入一个元素后，如果空间未重新分配，指向插入位置之前的元素的迭代器依然有效，但指向插入元素之后元素的迭代器全部失效。

### Deque迭代器失效总结

1.对于deque，插入到除首尾位置之外的任何位置都会导致迭代器、指针和引用都会失效，如果在首尾位置添加元素，迭代器会失效，但是指针和引用不会失效。

2.如果在首尾之外的任何位置删除元素，那么指向被删除元素外其他元素的迭代器都会失效。3.如果在其首部和尾部删除元素则只会使指向被删除元素的迭代器失效。

### 关联型容器迭代器失效

删除当前的迭代器，仅仅会使当前的迭代器失效，只要erase时，递增当前迭代器即可。




## 什么是函数调用约定？

函数调用约定就是对函数调用的一个约束和规定，描述了函数参数是怎么传递和由谁清除堆栈的。它决定了，函数参数传递的方式（是否采用寄存器传递参数，采用哪个寄存器传递参数，参数压栈的顺序等），函数调用结束后栈指针由谁恢复（被调用的函数恢复还是调用者恢复），函数修饰名的产生方法。

__stdcall：是standardcall的缩写，是C++的标准调用方式，规则如下：所有参数从右到左依次入栈，如果是调用类成员的话，最后一个入栈的是this指针。被调用函数自动清理堆栈，返回值在EAX。函数修饰名约定：VC将函数编译后会在函数名前面加上下划线前缀，在函数名后加上“@”和参数的字节数。

__cdecl：是C DECLaration的缩写（declaration，声明），表示C语言的默认函数调用方法，规定如下：所有参数从右往左依次入栈，所有参数由调用者清除，称为手动清栈。返回值在EAX中。函数修饰名约定：VC将函数编译后会在函数名前面加上下划线前缀，由于由调用者清理栈，所以允许可变参数函数存在。

__fastcall：是快速调用约定，通过寄存器来传送参数，规则如下：用ECX和EDX传送前两个双字（DWORD）或更小的参数，剩下的参数仍然自右向左压栈传送。被调用函数在返回前清理传送参数的内存栈，返回值在EAX中。函数修饰名约定：VC将函数编译后会在函数名前面加上“@”前缀，在函数名后加上“@”和参数的字节数。

\__thiscall：是唯一一个不能明确指明的函数修饰符，thiscall只能用于处理C++类成员函数的调用，同时thiscall也是C++成员函数缺省的调用约定，由于成员函数调用还有一个this指针，因此必须特殊处理，规定如下：采用栈传递参数，参数从右向左入栈，如果参数个数确定，this指针通过TCX传递给被调用者，如果参数个数不确定，this指针在所有参数压栈后被压入堆栈。对参数个数不确定的，调用者清理堆栈，否则由被调函数清理堆栈，__thiscal不是关键字，程序员不能使用l

\__pascal：与__stdcall一样，在VC中已经被废弃





## 使用条件变量的时候需要注意什么？

当signal先于wait时，该信号会丢失，不会被后续的wait捕获。

因此，在生产者消费者模型中，应该先释放互斥锁，再发送唤醒信号。

只是这样的话，信号还是可以丢失。假设线程A获取了锁，然后发现条件变量不满足，于是它释放锁，在A进入睡眠前，如果线程B发出唤醒信号，则该信号会丢失。不过好在c++的variable_condition的wait方法中，释放锁和进入睡眠是原子操作，因此中间不会插入其他线程的行为。



## Linux中的信号有哪些？

SIGINT：终端终端符，默认动作：终止。可以被捕获。当用户按中断键（Ctrl+C）时，终端驱动程序产生此信号并发送至前台进程组中的每一个进程，当一个进程在运行时失控，特别是在终端输出大量信息时，常用此信号终止它。

SIGQUIT：终端退出符，默认动作：终止+core。当用户在终端按退出键（Ctrl+\）时，终端驱动程序产生此信号，并发送给前台进程中所有进程，此信号不仅终止前台进程组，同时产生一个core文件。

SIGILL：非法硬件指令，默认动作：终止+core。此信号表示进程已执行一条非法硬件指令

SIGRAP：硬件故障，终止+core。指示一个实现定义的硬件故障

SIGBUG：硬件故障，终止+core。指示一个实现定义的硬件故障，当出现某些类型的内存故障时，常产生此信号。

SIGKILL：强制终止，不能被捕获，它向系统管理员提供一个可以杀死任一进程的可靠方法

SIGTERM：请求终止，但是该信号可以被捕获

SIGSTOP：暂停。不能被捕获。

SIGCONT：继续。不能被捕获。





## 什么是尾递归？

尾递归时递归的一种特殊情形，尾递归时一种特殊的尾调用，即在尾部直接调用自身的递归函数。核心思想是边调用便产生结果。

原理：当编译器检测到一个函数调用是尾递归的时候，它会覆盖当前的活动记录而不是在栈中创建一个新的。编译器可以做到这一点，因为递归调用是当前活跃期内最后一条待执行的语句，于是当这个调用返回时栈帧中并没有其他事情可以做，因此也就没有保存栈帧的必要了，通过覆盖当前的栈帧而不是在其之上重新添加一个，这样所使用的栈空间就大大缩减了，这使得实际的运行效率会变得更高。

特点：在尾部调用的是函数自身，可通过优化使得计算仅占用常量栈空间。



## 函数调用进行的操作：

函数调用分为以下几步：

1. 参数入栈，将参数按照函数调用约定依次压入栈中
2. 返回地址入栈，将当前指令的下一条指令的地址入栈，供函数返回使用
3. 进入被调函数，根据函数名找到函数入口，跳转
4. 开辟新的栈帧：
    1. ebp压栈，push ebp
    2. 将esp的值赋给ebp, move ebp esp
    3. 给新栈帧分配空间



函数返回分为以下几步：

1. 将返回值保存到eax寄存器
2. 恢复并回收栈帧空间
3. 将栈底恢复到ebp位置
4. ebp出栈，即恢复ebp位置 



## make_shared有什么优势

性能优化。std::make_shared 在性能上通常比直接使用 new 创建 std::shared_ptr 更好。这是因为 std::make_shared 会一次性分配用于存储对象和控制块（包含引用计数等信息）的内存，而使用new创建要创建智能指针本身和共享控制块。







## IPv4地址，网络地址，子网掩码

IPv4地址 & 子网掩码 = 网络地址

网络地址表示一段IP地址，有许多主机地址共享同一个网络地址。

但我们如何知道一个网络地址下可以分配多少个主机地址呢？此时我们需要知道一个网络地址使用的子网掩码有多少位，因此，CIDR网络地址表示法对网络地址后加了/x，其中x表示子网掩码的长度，例如有一个IPv4地址 192.168.50.10，它的子网掩码是255.255.192.0，那么它的子网掩码有18位，网络地址是 192.168.50.10 & 255.255.192.0 = 192.168.0.0，因此它的网络地址的CIDR表示法就是 192.168.0.0/18。





## 4种NAT技术类型 https://blog.csdn.net/weixin_55807049/article/details/122746836

### 1.Static NAT

网关有一个可以分配的公网段，将私网IP和公网IP进行一一对应。

### 2.Dynamic NAT

网关有一个可以分配的公网地址池，路由器将PC的私网IP地址替换为空闲的公网IP地址，然后访问Internet。公网地址和私网地址仍然是一一对应的，无法提高公网地址的利用率。

### 3.NAPT(Network Address Port Translation)

从地址池中选择地址时，网络地址和端口转换 (NAPT) 不仅会转换 IP 地址，还会转换端口号。可以节省IP地址。

### 4.Easy IP

特殊的NAPT，没有地址池，所有的私网地址都只能映射到一个公网地址，然后通过端口号来区分。





## 什么是Restful编程风格？

RESTfuI是一种基于 HTTP 协议的软件设计风格，用于构建网络应用程序和服务。它的核心思想是将网络资源视为一种“状态〞，并通过 HTTP 协议进行数据的传输和操作的执行。具体来说，RESTful使用 URI（统一资源标识符）来定位资源，并使用HTTP的各种操作方法（如 GET、POST、PUT 和 DELETE）来对这些资源的状态进行更新和管理。此外，RESTful 设计是无状态的，这意味着服务器不会维持与客户端的连接状态，每次请求都是独立的。这样的设计使得系统更加灵活和易于扩展，能够轻松地处理并发请求和负载均衡。





## HTTP

### 1.什么是HTTP

HTTP全称叫HyperText Transfer Protocol，中文叫超文本传输协议。它是一个用于点对点传输超文本的应用层协议。超文本是指文字、图片、视频等数据的混合体，最关键的是还有超链接，能够从一个超文本跳转到另一个超文本。HTML就是最常见的一种超文本。

我们把超文本的请求方称为HTTP客户端，大多数情况是浏览器，把超文本的提供方称为服务端，大多数情况是Web Server。

### 2.HTTP的工作原理

HTTP的工作原理是基于两种报文的。客户端发送请求报文，服务端回复响应报文。

#### 请求报文

请求报文的结构分为请求行、请求头、请求体。其中，请求行由请求方式、URL和版本号构成。

```
<method><request-URL><version> <headers> <entiry-body>
```

在Restful软件设计风格中，HTTP的每一种请求方式都有各自的含义：

+ GET：用于从服务器获取数据。它是幂等的。
+ POST：用于提交数据到服务器。非幂等的。
+ PUT：与POST都是提交数据，但PUT是用来更新一个已经存在的实体。
+ DELETE：从服务器删除数据。

请求的URL是指请求的路径，通常是由服务器的域名加服务器上资源的路径构成的。这个URL可能请求的是静态资源，则服务器返回对应的数据，如果请求的是动态资源，那么服务器会调用对应的Servlet去执行函数，然后返回函数的返回值。

请求行的最后是版本号。HTTP最有名的几个版本是HTTP1,1、HTTP2.0、HTTP3.0。

请求头是按照key-value来组织的，有许多字段，例如：

+ Content-Length：表示请求体的长度。由于HTTP一直到2.0都是用的TCP，TCP是面相字节流的，会有粘包问题。所以HTTP在应用层必须能够处理包的分界线。请求行和请求头中的每个键值对都是用回车和换行符来分隔的，请求头结束的时候还有一个空行。请求体的长度就是用Content-Length来标识的。
+ User-Agent：客户端浏览器类型、操作系统类型等等。
+ Accept-Language：客户端接受的语言。
+ Accept-Encodings：客户端可识别的编码方式。
+ Cookie：客户端携带的Cookie数据。
+ Connection：表示是否启用长连接。
+ 等等

请求体通常用于携带数据，GET方法因为是从服务器取数据，所以通常没有请求体，如果它有参数的话是直接放在URL后面；POST方法用于提交数据，这些数据就放在请求体中。

#### 响应报文

响应报文由响应行、响应头和响应体构成。其中，响应行由版本号、状态码和状态码说明构成。

```
<version><status><reason-phrase> <headers> <entity-body>
```

响应行的版本号也就是HTTP的版本号。

状态码和状态码说明是表达对HTTP请求的响应结果，一般有以下几种状态码：

+ 1xx：是一种中间状态，表示请求已经接受，服务器正在处理。例如101表示协议切换，从HTTP切换WebSocket协议时使用。
+ 2xx：请求成功。例如200表示ok。
+ 3xx：重定向。例如301表示永久重定向，所请求的资源被移动了别处的话就返回这个状态码。304表示重定向到客户端的本地缓存。
+ 4xx：客户端错误。例如404表示客户端请求了不存在的资源。403表示客户端权限不够。
+ 5xx：服务端错误。例如502 Bad Gateway，通常是网关无法获得后台服务器的正常响应，

响应头的常用字段有：

+ Content-Length：响应体的长度。
+ Expires：过期时间。因为客户端会缓存响应，在过期之前再次访问的话可以使用缓存。HTTP有具体的缓存策略。

响应体就是要请求的数据，可能是HTML，也可能是JSON格式的数据等等。



综上，HTTP协议的工作原理就是客户端发送请求报文，服务端回复响应报文。

关于报文的传输模式，可以从HTTP协议演化的角度去说明。



### 3.HTTP协议的演化

在HTTP1.1之前，每个HTTP请求发送前都需要建立TCP连接，响应后关闭连接。我们知道HTTP传输的是超文本，所以客户端极有可能连续请求非常多的资源，这样效率极低。所以在HTTP1.1时，引入了长连接，就是除非显式的关闭TCP连接，否则HTTP就保持并复用TCP连接。

HTTP1.1的另一个重大改进是支持管道传输，在这之前HTTP是停等式传输。管道传输提高了HTTP的传输效率。



HTTP2.0引入了一些新的优化。总结为4个方面。

1. 头部压缩。HTTP请求头和响应头其实有点大，如果要提交的数据量很小的话，其实有效负载率很低。因此，HTTP2.0中，如果客户端发送许多请求头相同的请求，那么会使用HPACK算法进行压缩。这是一种结合了压缩表、哈夫曼编码等算法的算法。
2. 二进制格式。在HTTP1.1中，请求和响应的头部字段都是按照文本格式编码的，很浪费空间。HTTP2.0采用二进制编码格式。
3. 支持并发传输。在HTTP1.1中，虽然实现了HTTP请求的管道化传输，但是服务器在处理时还是只能顺序处理，如果有一个请求卡住，那么后续的请求都被阻塞。在HTTP2.0中，引入了stream的概念，每个请求都会有一个所属的stream，这些stream虽然复用一条TCP连接，但是他们之间是隔离的，可以并发传输。这样就解决了HTTP的队头阻塞问题。但由于底层还是用的TCP，所以还是会有TCP层面的队头阻塞问题。
4. 服务器主动推送。HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。

HTTP3.0的变化更大。

1. 采用基于UDP的QUIC传输协议。TCP的可靠性保障中，如果接受窗口中有未接收到的字节，那么整个窗口都无法向前移动，而且应用程序也不能从内核拿到数据。这就是TCP层面的队头阻塞。

    在HTTP2.0中，多个Stream共用一个TCP连接，所以如果发生TCP的队头阻塞，那么后续到达的其他Stream的数据也无法被接收。所以HTTP3.0采用基于UDP的QUIC协议，QUIC为每个Stream分配了单独的滑动窗口，于是当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。

    此外，QUIC的流量控制有Stream级别和Connection级别的。Stream级别是针对每个Stream独立的接受窗口进行的，Connection级别是对所有Stream的窗口总和进行的。

    QUIC采用了与TCP相同的拥塞控制。

2. 更快的连接建立。HTTP2.0使用的TCP协议在建立连接时，TCP三次握手加TLS握手，总共需要3个RTT时间。而QUCI协议中只需要1个RTT。

3. 连接迁移功能。因为HTTP3.0是基于UDP的，所以客户端和服务端的连接其实是逻辑连接，而不是TCP的物理连接。这个逻辑连接就是用Stream ID来标识的。所以如果客户端从切换了WIFI之类的操作使得IP地址改变，也不会导致连接被破坏。



### 4.HTTPS

HTTP 的报文是明文传输的，会泄漏请求参数、请求数据等等。

HTTPS 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议。HTTPS与HTTP的区别在于：

1. 机密性：使用混合加密传输。在TLS握手阶段，采用非对称加密和服务端商议出一份对称密钥。在之后的传输过程中使用对称加密通信。解决了窃听的风险。
2. 完整性：服务端对报文进行摘要，然后对摘要进行数字签名，客户端可以用公钥验证数字签名。解决了报文被篡改的风险。
3. 使用数字证书保证公钥是可信的。



### 5.HTTP的缓存策略

HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。

#### 1.强制缓存

强制缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。

强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：

- `Cache-Control`， 是一个相对时间；
- `Expires`，是一个绝对时间；

如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，**Cache-Control 的优先级高于 Expires**。

Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；
- 浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器；
- 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。

#### 2.协商缓存

协商缓存与强制缓存的区别是，第二次访问时，浏览器仍然向服务器发出请求，由服务器选择是否让浏览器使用缓存。如果不使用，服务器就正常返回数据，如果使用，就返回304重定向，让浏览器使用缓存。

服务器作出是否使用缓存的判断有两套依据：

1. 基于时间的判断。请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段实现。
    + 服务器在响应头中会将资源的最后修改时间放入 last-modified 字段。
    + 当浏览器第二次请求资源时，它会将第一次请求时收到的响应头中的资源最后修改时间放入本次请求头的 if-modified-since 字段。用于告知服务器它现在所持有的资源的版本。
    + 服务器收到含有if-modified-since字段的请求后，检查在时间之后资源是否发生过修改，如果没有则返回304。
2. 基于版本号的判断。工作原理与基于时间的判断一样，只不过是借助请求头中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段来实现。
    + 服务器在响应头中会将资源当前的版本号放入 etag 字段。
    + 当浏览器第二次请求资源时，它会将第一次请求时收到的响应头中的资源版本号放入本次请求头的 if-none-match 字段。用于告知服务器它现在所持有的资源的版本。
    + 服务器收到含有 if-none-match 字段的请求后，检查与资源当前的版本号是否一致，一致则返回304。



综上，一共有3组字段来支持HTTP的缓存机制。具体的工作流程是：先进行强缓存判断，不命中时再进行协商缓存，其中优先基于版本号的判断，如果还不命中，最终进行基于时间的判断。

流程图如下：

<img src="/Users/yv_zhanghao/Documents/MarkdownFiles/Network/1.jpg" style="zoom:70%;"  >



## HTTP是全双工吗？

单工： 数据传输只允许在一个方向上的传输，只能一方来发送数据，另一方来接收数据并发送。

半双工：数据传输允许两个方向上的传输，但是同一时间内，只可以有一方发送或接受消息。

全双工：同时可进行双向传输。例如：`websocket`。

http1.1是半双工，http2.0是全双工(支持服务器推送)。





## TCP

TCP的全称是Transmission Control Protocol，中文叫传输控制协议。它是一个用于面向连接的、可靠的、基于字节流的传输层协议。由于传输层是按照端口号来区分应用程序的，所以TCP的包头中源端口号和目的端口号。TCP包的包头是20-60字节。

下面从3个角度来说明TCP的工作原理。

### 1.面向连接

TCP是端到端传输的协议，这里的端是指某台主机上的一个引用程序，使用IP地址+端口号来标识。在开启传输之前，TCP需要进行3次握手。

1. 客户端发送SYN报文，携带序列号给服务器，请求建立连接，进入SYN_SENT状态。
2. 服务端收到序列号后，返回ACK和自身的SYN序列号，ACK为收到的syn+1，并进入半连接状态，SYN_RCVD状态。
3. 客户端收到服务端的ack和序列号后，将序列号加一作为ack回复给服务端，进入已连接状态。服务端收到ack后也进入已连接状态。

在关闭连接时。要进行4次挥手。关闭连接可能是任意一方发起的，这里以客户端发起举例。

1. 客户端发送FIN报文，请求关闭连接。这表明客户端没有要向服务端发送的数据了。
2. 服务端返回ACK，进入CLOSE_WAIT状态。
3. 服务端发送完成传输后，发送FIN报文，表面服务端没有要向客户端发送的数据了。
4. 客户端返回ACK，等待两个MSL时间后关闭连接。MSL(Maximum Segment Lifetime)是报文最长存活时间，这有两个原因：
    1. 防止历史连接中的数据，被后面相同四元组的连接错误的接收；
    2. 保证「被动关闭连接」的一方，能收到ACK而正确的关闭；



### 2.可靠性

TCP能够保证将传输的数据按顺序无误的交给应用层。

这是由下面的机制实现的：

1. 序号机制和ACK。TCP流的每个字节都有序号，一个TCP包的负载的第一个字节的序号会被记录到包头中。接收方会对已经累计接收到的字节进行ACK确认，这样发送方就能知道哪些字节成功传输了，而哪些失败了。
2. 校验和机制。TCP包头有一个校验和字段，如果接收方校验失败，则不会对该包进行ACK。
3. 重传机制。超时重传是指发送方会对每个已发送的包进行计时，在指定时间内没有收到ACK就要重发这个包。快速重传是指发送方连续收到3个同样的ACK，则说明这个ACK的下一个包丢失了，且后续的包已经到到达了，此时发送方直接重传这个包。
4. 流量控制。为了使得发送方的发送速率能够匹配接受方的接收速率。发送方有发送窗口，接收方有接收窗口。
    1. 为了避免窗口关闭问题，发送方要定期发送窗口探测报文。
    2. 为了避免糊涂窗口综合症，接收方不返回小窗口，发送方采用Nagle算法延迟发送。
5. 拥塞控制。为了避免在网络拥塞的情况下高速发送数据，使得网络更加恶化。
    1. 慢启动
    2. 拥塞避免
    3. 拥塞发生
    4. 快速恢复



### 3.字节流

首先说一下TCP是如何分包的。由于TCP的可靠性传输，TCP的包如果丢失或有差错则需要整个包进行重传，如果传输层的TCP包很大的话，经过IP层分片后，可能会对应多个IP包，这些IP包是分开传输的， 那么只要有一个发生错误，则其他IP包都要重传，这样效率很低。因此，TCP在传输层按照MSS对字节流进行分割，MSS指Maximum Segment Size。也就是TCP层一个包叫做一个段。每个段的最大长度被设置为小于MTU，也就是以太网的最大包长。这样的话，一个段发生错误不会牵连到其他段。

因此，应用层的一个报文message，发给传输层之后会被TCP分成多个段进行传输。同时由于缓冲区的存在，发送方可能把下一条消息的一部分也拿到当前TCP包中进行传输，这就是粘包问题。因此，在接收方看来收到的数据就是一个字节流，要从中提取出完整的应用层消息，需要应用层自己来设置边界。具体方法有：

1. 固定长度消息。
2. 特殊字符来作为边界。HTTP就是一个很好的例子，请求头中的每个字段结尾都有回车和换行符。请求头结尾还有一个空行。
3. 消息中携带长度字段。例如HTTP的Content-Length。



## TCP和UDP的区别

1. TCP面向连接，需要3次握手4次挥手，而UDP是无连接的，直接发送。
2. TCP是可靠传输，保证数据按序完整的到达，而UDP是尽力传输，不做任何保障。
3. TCP是基于字节流的，会有粘包问题，而UDP是基于数据包的，没有粘包问题。
4. TCP是有状态的，因为TCP的重传机制需要记录消息是否被接收。UDP是无状态的，消息从主机进入网络后就不再留存记录了。
5. TCP传输效率比UDP低。这是因为TCP的复杂机制，包括ACK机制、流量控制、拥塞控制等。
6. TCP头部开销更大，包头20-60字节，而UDP只有8字节。
7. TCP只支持一对一传输，UDP支持广播。



## TCP和UDP可以绑定到同一个端口吗？

可以。服务端的内核网络协议栈在处理接收到的包时，从下到上处理，在网络层时，根据IP包头中的字段判断应该把IP Payload交给上层的那个模块处理。TCP和UDP是完全不同的两个模块，一个IP包的负载只会被传递到其中的一个。这两个模块内部会根据传输层包的端口来决定交给哪个Socket。所以TCP和UDP的网络端口号是隔离的。



## 多个TCP服务进程可以绑定到同一个端口吗？

不行。除非这些进程使用主机上不同的IP。



## 多个TCP客户端进程可以绑定同一个端口吗？

bind 函数虽然常用于服务端网络编程中，但是它也是用于客户端的。

前面我们知道，客户端是在调用 connect 函数的时候，由内核随机选取一个端口作为连接的端口。

而如果我们想自己指定连接的端口，就可以用 bind 函数来实现：客户端先通过 bind 函数绑定一个端口，然后调用 connect 函数就会跳过端口选择的过程了，转而使用 bind 时确定的端口。

针对多个客户端是否能绑定同一个端口，要看多个客户端绑定的 IP + PORT 是否都相同，如果都是相同的，那么在执行 bind() 时候就会出错，错误是“Address already in use”。



## Linux发送和接收网络包的流程

### 1.发送网络包

首先，应用程序会调用 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 层，内核会申请一个内核态的 sk_buff 内存，**将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区**。

接下来，网络协议栈从 Socket 发送缓冲区中取出 sk_buff，并按照 TCP/IP 协议栈从上到下逐层处理。

如果使用的是 TCP 传输协议发送数据，那么**先拷贝一个新的 sk_buff 副本** ，这是因为 sk_buff 后续在调用网络层，最后到达网卡发送完成的时候，这个 sk_buff 会被释放掉。而 TCP 协议是支持丢失重传的，在收到对方的 ACK 之前，这个 sk_buff 不能被删除。所以内核的做法就是每次调用网卡发送的时候，实际上传递出去的是 sk_buff 的一个拷贝，等收到 ACK 再真正删除。

接着，对 sk_buff 填充 TCP 头。这里提一下，sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame。

然后交给网络层，在网络层里会做这些工作：选取路由（确认下一跳的 IP）、填充 IP 头、netfilter 过滤、对超过 MTU 大小的数据包进行分片。处理完这些工作后会交给网络接口层处理。这里要注意，如果要进行IP分片，那么sk_buff在IP层就又进行了一次复制。

这一些工作准备好后，会触发「软中断」告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会从发送队列中读取 sk_buff，将这个 sk_buff 挂到 RingBuffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送。

当发送完成的时候，网卡设备会触发一个硬中断来释放内存，主要是释放 sk_buff 内存和清理 RingBuffer 内存。

最后，当收到这个 TCP 报文的 ACK 应答时，传输层就会释放原始的 sk_buff 。

#### 发送网络数据的时候，涉及几次内存拷贝操作？

第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。

第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。

第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。



### 2.接收网络包

当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 Ring Buffer ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达。

网卡通知操作系统网络报到达是通过向 CPU 发起硬件中断来完成的。当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。

硬件中断处理函数会做如下的事情：

- 需要先「暂时屏蔽中断」，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。
- 接着，发起「软中断」，然后恢复刚才屏蔽的中断。

至此，硬件中断处理函数的工作就已经完成。

硬件中断处理函数做的事情很少，主要耗时的工作都交给软中断处理函数了。

内核中的 ksoftirqd（kernel software IRQ daemon) 线程专门负责软中断的处理，当 ksoftirqd 内核线程收到软中断后，就会来轮询处理数据。ksoftirqd 线程会从 Ring Buffer 中获取一个数据帧，用 sk_buff 表示，从而可以作为一个网络包交给网络协议栈进行逐层处理。

首先，会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给网络层。

到了网络层，则取出 IP 包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。

传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据放到 Socket 的接收缓冲区。

最后，应用层程序调用 Socket 接口，将内核的 Socket 接收缓冲区的数据「拷贝」到应用层的缓冲区。

<img src="/Users/yv_zhanghao/Documents/MarkdownFiles/Network/2.jpg" style="zoom: 33%;" >



## RPC

RPC全称是Remote Procedure Call，中文叫远程过程调用。它的作用就是使得调用远程服务像调用本地方法一样方便。

RPC框架的核心组件有4个：

1. 客户端：服务的调用者
2. 客户端存根（Client Stub）：存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务存根。
3. 服务端存根（Server Stub）：接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理。
4. 服务端：服务的真正提供者。

一次 RPC 调用流程如下：

1. 服务消费者(Client 客户端)通过本地调用的方式调用服务。
2. 客户端存根(Client Stub)接收到调用请求后负责将方法、入参等信息序列化(组装)成能够进行网络传输的消息体。
3. 客户端存根(Client Stub)找到远程的服务地址，并且将消息通过网络发送给服务端。
4. 服务端存根(Server Stub)收到消息后进行解码(反序列化操作)。
5. 服务端存根(Server Stub)根据解码结果调用本地的服务进行相关处理
6. 服务端(Server)本地服务业务处理。
7. 处理结果返回给服务端存根(Server Stub)。
8. 服务端存根(Server Stub)序列化结果。
9. 服务端存根(Server Stub)将结果通过网络发送至客户端。
10. 客户端存根(Client Stub)接收到消息，并进行解码(反序列化)。
11. 服务消费方得到最终结果。

由此可见，RPC这个远程调用方法，包括了通信协议和序列化协议。

在通信协议方面，RPC也可以直接使用传输层的TCP，也可以复用HTTP进行传输。例如Google的gRPC就是利用HTTP2.0来进行网络传输的。

在序列化协议方面，RPC的定制化程度更高。只要客户端和服务端使用同样的序列化规则即可，因此RPC的远程调用传递的参数可以非常简洁。相比于只使用HTTP进行远程服务，RPC的效率更高。因此RPC通常使用在微服务集群内部的远程服务调用，而对外则使用更加复杂和通用的HTTP。





## Web Socket

Web Socket是在HTTP1.1之后提出的应用层协议，相比于HTTP1.1它的主要改进是全双工的通信机制，因此在对实时交互或者服务器推送有要求的场景下可能会使用Web Socket。

在HTTP1.1中，服务器不能主动推送数据到客户端。只能使用客户端定时轮询或者长轮询机制。

1. 定时轮询就是客户端以较高的频率发送HTTP请求，检查是否要更新数据。例如微信公众号平台扫码登录。
2. 长轮询就是客户端设置HTTP请求的过期时间很长，服务器在收到请求后可以等待一段时间再回复。例如百度网盘网页版，在登录时会等待服务器的响应时间较长，只要手机端点击登陆，服务器就会立刻响应。

像登录这种简单的场景可以使用轮询机制，但如果是网页游戏这种场景，就需要全双工机制了。

Web Socket建立连接的方式是先通过TCP3次握手建立HTTP连接，然后客户端在HTTP请求头中使用 Upgrade: WebSocket 字段来请求升级协议。服务器使用状态码101来响应。之后客户端和服务端就可以使用Web Socket进行通信了。





## Socket 编程

### 1.TCP

客户端：socket, connect, read/write, close

服务端：socket, bind, listen, accpet, read/write, close

#### 客户端的connect

TCP的三次握手是在客户端使用connect后开启的，当服务器返回ack时，connect发送第三次握手并返回。此时，客户端已经可以向服务端发送数据了。但是注意，虽然客户端已经是ESTABLISH状态了，但是第三次握手如果在网络中丢失，那么服务端就还没有建立连接，服务端在指定时间内收不到ack就会重传syn+ack，直到建立连接或删除半连接。

#### 服务端的listen

服务端对socket在listen这一步会创建两个队列，半连接队列和已连接队列。

+ 半连接队列。其中存储的是只经过两次握手，正在等待客户端第三次握手的连接。

    + 该队列中的socket都处于SYN_RECV状态。
    + 该队列底层使用哈希表实现。因为当服务端收到客户端的第三次握手时，它需要找到之前存储的半连接socket，因此使用哈希表可以实现O(1)时间复杂度建立连接。

+ 已连接队列。已经完成三次握手，正在等待服务端使用accpet取走的连接。

    + 该队列中的ESTABLISHED状态。

    + 该队列底层使用链表实现。因为accept函数只需要从中取走一个已建立的连接即可，并不关心是哪一个，所以可以直接取出头节点socket。

      ​    

服务端调用listen后，有操作系统内核将与到达的SYN消息建立连接，而用户进程不需要管理这些事情，所以listen函数不会阻塞。内核会将经过两次握手的socket放在半连接队列，如果收到第三次握手则将其转移到已连接队列。

**由此可见，即使不调用accept，tcp连接也可以正常建立。**

listen函数除了接收socket作为参数，还接受一个backlog参数。早期它的含义是半连接队列的最大长度，现在它的含义是和内核参数共同决定半连接队列和已连接队列的somaxconn(socket maximum connection)最大长度。

+ 已连接队列的最大长度：min(somaxconn, backlog)
+ 半连接队列的最大长度稍微复杂，但也和backlog有关系。
    + 当 max_syn_backlog > min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = min(somaxconn, backlog) * 2;
    + 当 max_syn_backlog < min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = max_syn_backlog * 2;

在默认行为下，如果半连接或已连接队列满了，那么新的连接请求就会被丢弃。

#### 服务端的accept

应用程序在listen后会调用accept函数，这时可能会发生阻塞。

accept函数的作用就是从已连接队列中取出一个socket。如果调用accept时已连接队列为空，则该函数会阻塞等待。

在取出已连接socket后，主线程需要让其他线程处理该socket的通信，而自己本身需要再次去调用accept来检查是否有新的已连接socket。



## 如何防御SYN攻击

### 1.增大半连接队列

修改内核参数。增大 tcp_max_syn_backlog 和 somaxconn等参数。指标不治本。

### 2.减少SYN+ACK的重传次数

当服务器的半连接队列中的socket接收不到第三次握手时，有可能是正常连接只不过发生了丢包。所以服务器会重传SYN+ACK，希望能够得到客户端的第三次握手。只有在重传达到上限后才会主动删除半连接。所以为了防止半连接占用太多资源，可以减少重传次数。

### 3.开启 tcp_syncookies 功能

该机制的核心思想就是在完成三次握手前不为socket分配资源。因此，就不会占用半连接队列。那么原本半连接socket需要维护的信息，就是通过写在第二次握手的初始化序列号里，从而让客户端第三次握手时自带该信息。

net.ipv4.tcp_syncookies 参数主要有以下三个值：

- 0 值，表示关闭该功能；
- 1 值，表示仅当 SYN 半连接队列放不下时，再启用它；
- 2 值，表示无条件开启功能；

当启用该功能时，工作步骤如下：

- 服务端收到 SYN 后，根据算法，计算出一个 `cookie`值；
- 将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；
- 服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。
- 最后应用程序通过调用 `accpet()` 接口，从「 Accept 队列」取出的连接。





## DHCP

DHCP全称Dynamic Host Configuration Protocol，中文为动态主机配置协议。该协议允许DHCP服务器动态的为客户端分配IP地址。

先说明一点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。

DHCP分配IP地址的过程如下：

1. 客户端首先发起 **DHCP 发现报文（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP **广播**通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。
2. DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文（DHCP OFFER）** 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文携带服务器提供的 IP 地址、子网掩码、默认网关、DNS 服务器以及 **IP 地址租用期**。
3. 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文（DHCP REQUEST**进行响应，回显配置的参数。
4. 最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数。

一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。

如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：

- 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。
- 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。

可以发现，DHCP 交互中，**全程都是使用 UDP 广播通信**。

如果 DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，那不是每个网络都要配一个 DHCP 服务器？所以，为了解决这一问题，就出现了 **DHCP 中继代理**。有了 DHCP 中继代理以后，**对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。**

- DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以**单播**的形式发给 DHCP 服务器。
- 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端 。





## ICMP

ICMP全称是Internet Control Message Protocol，中文叫互联网控制报文协议。它是用于传递互联网连接状态信息的网络层协议。

ICMP 大致可以分为两大类：

- 一类是用于诊断的查询消息，也就是「**查询报文类型**」，例如：

    - 回送请求（Echo Request）
    - 回送应答（Echo Reply）

    回送请求和回送应答的使用例子是ping程序。客户端进程发送回送请求想目标主机，如果目标主机能返回回送应答，则目标主机可达。

- 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」，例如：

    - **原点抑制（Source Quench）**：如果某个源主机向目的主机快速地发送数据包，但目的主机来不及处理，就会向源主机发出该类型的 ICMP 包，提醒源主机放慢发送速度。
    - **重定向（Redirect）**：如果某个源主机向网络中发送一个 IP 包，路径中某个路由器收到这个 IP 包，对照其路由表，发现自己不应该接收该包(包需要原路返回，或者不是最佳路由路径)，就会向源主机发送该类型的 ICMP 包，提醒源主机修改自己的路由表，下次路由到另外一个更好的路由器。
    - **分片错误**：如果某个源主机在发送一个 IP 包之前，对该 IP 包中的首部字段 DF 位设为 1，也就是“分片禁止位=1”，表示该包在传输的过程中不允许分片，但是中间某个路由器允许传输的最大路径 MTU 小于该包大小，需要分片才能传输，但是由于设置不分片位，路由器会将该包丢弃，并向源主机发送一个携带 MTU 信息的 ICMP 包，提醒源主机下次发包的大小不应超过该 MTU 的值。**traceroute程序利用该报文类型来探测两个主机之间的链路层MTU，实现方式就是逐步调整UDP包的大小，探测不分片的最大长度**。
    - **超时错误**：超时定义了数据包在网络中存活的最长时间，IPv4 中的 TTL 字段和 IPv6 中的 Hop Limit 字段都表示了这层意思，它们是一个整数值，会随着经过的路由器而递减，当减为 0 时，就认为该 IP 包超时，然后当前减为 0 的路由器会向源主机发送 ICMP 包，通知它发生了超时错误。**traceroute程序利用该报文类型探测两个主机之间路径上的路由器，实现方式就是递增TTL，导致每一个节点都会返回一次差错报文。traceroute请求目标主机一个没有被监听的端口，当到达主机后，返回的差错报文类型将是端口不可达**。





## UDP组播

组播报文的目的地址使用D类IP地址。在ip组播环中，数据包的目的地址不是一个，而是一组，形成组地址。所有的信息接收者都加入到一个组内，并且一旦加入之后，流向组地址的数据立即开始向接收者传输，组中的所有成员都能接收到数据包。组播组中的成员是动态的，主机可以在任何时刻加入和离开组播组。

用同一个IP多播地址接收多播数据包的所有主机构成了一个主机组，也称为多播组。一个多播组的成员是随时变动的，一台主机可以随时加入或离开多播组，多播组成员的数目和所在的地理位置也不受限制，一台主机也可以属于几个多播组。此外，不属于某一个多播组的主机也可以向该多播组发送数据包。  

#### **组播地址**

1. 组播组可以是永久的也可以是临时的。组播组地址中，有一部分由官方分配的，称为永久组播组。永久组保持不变的是它的ip地址，组中的成员构成可以发生变化。永久组播组中成员的数量都可以是任意的，甚至可以为零。那些没有保留下来供永久组播组使用的ip组播地址，可以被临时组播组利用。
2. 224.0.0.0～224.0.0.255为预留的组播地址（永久组地址），地址224.0.0.0保留不做分配，其它地址供路由协议使用；
3. 224.0.1.0～224.0.1.255是公用组播地址，可以用于Internet；
4. 224.0.2.0～238.255.255.255为用户可用的组播地址（临时组地址），全网范围内有效；
5. 239.0.0.0～239.255.255.255为本地管理组播地址，仅在特定的本地范围内有效。

组播是一对多的传输方式，其中有个组播组的 概念，发送端将数据向一个组内发送，网络中的路由器通过底层的IGMP协议自动将数据发送到所有监听这个组的终端。至于广播则和组播有一些相似，区别是路由器向子网内的每一个终端都投递一份数据包，不论这些终端是否乐于接收该数据包。UDP广播只能在内网（同一网段）有效，而组播可以较好实现跨网段群发数据。

### 组播的原理：

组播首先由一个用户申请一个组播组，这个组播组被维护在路由器中，其他用户申请加入组播组，这样当一个用户向组内发送消息时，路由器将消息转发给组内的所有成员。如果申请加入的组不在本级路由中，如果路由器和交换机允许组播协议通过，路由器将申请加入的操作向上级路由提交。**广域网通信要经过多级路由器和交换机，几乎所有的网络设备都默认阻止组播协议通过(只允许本网段内，不向上级提交)，这使得广域网上实现组播有一定局限**。





## IGMP

IGMP全称 Internet Group Management Protocol，中文是互联网组管理协议。他是工作在主机和最后一跳路由器之间网络层协议。

主机可以通过IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。

IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。

IGMP有两种工作机制：

### 1.常规查询与响应

1. 路由器会周期性发送目的地址为 `224.0.0.1`（表示同一网段内所有主机和路由器） **IGMP 常规查询报文**。
2. 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10 秒，计时器超时后主机就会发送 **IGMP 成员关系报告报文**（源 IP 地址为自己主机的 IP 地址，目的 IP 地址为组播地址）。如果在定时器超时之前，收到同一个组内的其他主机发送的成员关系报告报文，则自己不再发送，这样可以减少网络中多余的 IGMP 报文数量。
3. 路由器收到主机的成员关系报文后，就会在 IGMP 路由表中加入该组播组，后续网络中一旦该组播地址的数据到达路由器，它会把数据包转发出去。







## 中断

https://blog.csdn.net/qq_38089448/article/details/132457300

硬中断是外部硬件产生的,包括不可屏蔽中断NMI与可屏蔽中断INTR，硬中断可以嵌套。

软中断是内部产生的，是不可屏蔽中断，不可以嵌套。



## 逻辑地址、线性地址、物理地址

https://blog.csdn.net/qq_45675126/article/details/132269108

逻辑地址（logical address）:机器语言指令中用来指定一个操作数或一条指令的地址。每一个逻辑地址都由一个段和偏移量组成，偏移量指明了从段开始的地方到实际地址之间的距离。例如，c语言取指针的操作（&），这个值是逻辑地址，它是相对于你当前进程数据段的地址，不是物理地址。逻辑地址由两个16位的地址分量构成，一个为段基值，另一个为偏移量。两个分量均为无符号数编码。

线性地址（linear address）:也称虚拟地址（virtual address），是一个32位无符号整数，可以用来表示高达4GB的地址，是逻辑地址和物理地址之间的中间层，在分段部件中，逻辑地址就是段中的偏移地址，加上基地址就是线性地址。

物理地址（physical address）:用于内存芯片级内存单元寻址，它们从微处理器的地址引脚发送到内存总线上的电信号相对应。物理地址通常由32位或36位无符号整数表示。

> x86 CPU的内存管理设计的方案是 逻辑地址->线性地址->物理地址，也就是强制使用段页式内存管理。然而，linux系统不适用段式，只使用页式，所以就将程序的所有段映射到同一个线性空间，也就是所有段的基地址都是0，那么逻辑地址的所有位就都用来表示段内偏移量，也就等于线性地址了。而在 x86_64 的 CPU上已经抛弃了分段。



## 线程的3种类别

### 1.用户态线程

用户态线程只能实现并发，不能实现并行，操作系统对用户态线程无感知。

### 2.内核态线程

内核态线程在多核CPU上可以并行，有内核来进行调度。

### 3.轻量级进程

LWP是内核态线程与用户态线程的中间层，一个LWP对应一个内核态线程，对应一或多个用户态线程。LWP工作在用户空间，它本质上就是一组共享虚拟地址的进程，但由于属于同一组的LWP切换时上下文内容切换很少，更像线程的概念，所以称为轻量级进程。





## 进程间通信和线程间通信

https://blog.csdn.net/Bingo_Nong/article/details/114626446

### 通信模式

单工、半双工、全双工这三个术语描述了不同类型的通信方式，它们之间的主要区别在于数据的传输方向和是否允许同时的双向通信。

1. **单工通信（Simplex）：**
    - **定义：** 单工通信是指数据只能在一个方向上传输的通信方式。
    - **特点：** 在单工通信中，通信双方有一个固定的发送方和接收方。一方只能发送数据，而另一方只能接收数据。传统的广播电台和电视广播就是单工通信的例子，听众和观众只能接收信息，而不能向广播台发送信息。
2. **半双工通信（Half-Duplex）：**
    - **定义：** 半双工通信是指数据可以在两个方向上传输，但不能同时进行，通信双方在不同时间段内交替发送和接收数据。
    - **特点：** 在半双工通信中，通信双方可以在同一通信链路上发送和接收数据，但不能同时进行。对讲机通信就是一个半双工通信的例子，一方说话时另一方只能听，反之亦然。
3. **全双工通信（Full-Duplex）：**
    - **定义：** 全双工通信是指数据可以在两个方向上同时进行的通信方式。
    - **特点：** 在全双工通信中，通信双方可以同时发送和接收数据，允许双向通信。典型的例子是电话通信，双方可以同时说话和听对方说话，实现了双向的交互通信。



进程间通信可以分为相同主机的进程之间通信和不同主机的进程通信。

对于相同主机：

### 1.管道

管道本身是一种半双工通信方式，它是一个先进先出的队列。但是使用时通常确定了发送方和接收方之后就按照单工来使用，用两条管道来模拟全双工。

匿名管道只能在具有亲缘关系的进程间通信，例如linux命令中的竖线，用完就销毁。

有名管道会被抽象成一个文件，支持任意进程间通信，例如linux中用命令mkfifo可以创建有名管道。

### 2.消息队列

消息队列是保存在内核中的消息链表。在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。

消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。

**消息队列不适合比较大数据的传输**，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 `MSGMAX` 和 `MSGMNB`，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。

**消息队列通信过程中，同样存在存在用户态与内核态之间的数据拷贝开销**，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。

### 3.共享内存

管道和消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那**共享内存**的方式，就很好的解决了这一问题。

现代操作系统对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。共享内存机制就是就是拿出一块虚拟地址空间来，映射到相同的物理内存中来实现通信。共享内存通常需要进行并发控制，例如使用互斥锁或信号量等等。

### 4.信号量

为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，**信号量**就实现了这一保护机制。 **信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。

### 5.信号

信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。

**1.执行默认操作**。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。

**2.捕捉信号**。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。

**3.忽略信号**。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程。



对于不同主机：

### 6.Socket通信

对于不同主机之间的进程通信，通常使用Socket通信。

Socket应用层和传输层通信的编程接口，使用时需要指定传输层的协议，最常用的就是TCP和UDP。

针对有连接、面向字节流的可靠传输TCP，Socket通信的基本模型是，客户端connect，然后read/write，最后close；服务端需要先bind，listen，accept，然后read/write，最后close。

针对无连接，面向数据包的不可靠传输UDP，Socket通信的基本模型是，客户端和服务端都是bind，sendto/recvfrom。



线程间通信：

如果是两个进程的线程，则等同于进程通信。

如果是一个进程的不同线程，则有：

1. 互斥量
2. 信号量
3. 条件变量



## 进程调度算法

### 1.先来先服务

每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。吞吐量极低。

### 2.短作业优先

它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。但是容易造成长任务饿死。

### 3.高响应比优先

每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：

优先权=(等待时间+任务要求执行的时间)/任务要求执行的时间。

### 4.时间片轮转(Round Robin)

每个进程被分配一个时间段，称为时间片（\*Quantum\*），即允许该进程在该时间段中运行。

- 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；
- 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

### 5.优先级调度算法

调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（\*Highest Priority First，HPF\*）调度算法。

进程的优先级可以分为，静态优先级和动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

### 6.多级反馈队列调度算法

多级反馈队列（\*Multilevel Feedback Queue\*）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；
- 当时间片用完后要将当前任务降低到下一个队列中，同时要定期提高所有任务所处的队列，以避免饥饿现象。





## Linux的6种IO模式

### 1.阻塞式IO

阻塞式IO会阻塞用户进程直到数据传输完成。如果内核缓冲区中没有数据可读，那么read函数会一直阻塞，直到有数据可读为止。在这段时间里，应用进程无法执行其他操作。(在调用accept的过程会发生阻塞直至有客户端和服务器建立连接)。

阻塞I/O模型通常适用于单线程、同步、串行的应用程序，比如文件传输、打印机等。

### 2.非阻塞式IO

非阻塞IO是指在进行输入输出操作时，程序不会阻塞等待结果返回，而是可以继续执行其他操作，等到结果返回时再去获取结果。实现非阻塞IO的方式一般是通过轮询或事件驱动的方式。轮询是指程序会不断地询问IO操作是否完成，如果没有完成就会继续执行其他操作，直到IO操作完成为止。事件驱动则是通过注册事件回调函数，当IO操作完成时自动调用该回调函数，从而实现非阻塞IO操作。

非阻塞I/O的accept函数不会阻塞，因为它是在非阻塞模式下工作的。当没有新的连接请求到达时，accept函数会立即返回-1。

### 3.IO多路复用

I/O多路复用是一种通用的高效I/O处理机制，它允许一个进程可以同时监视多个文件描述符（套接字），并且可以在其中任何一个文件描述符上等待数据可读或可写，从而实现并发I/O操作。/O多路复用机制通常由select、poll和epoll等系统调用实现。



#### 1.select

```c++
int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

它接收五个参数，分别是最大的fd值加1、可读fd集合、可写fd集合、异常fd集合和超时时间。

fd集合是bit数组，每个比特位代表一个文件描述符，文件描述符的值就是这个比特位的偏移量。

select函数在用户空间和内核空间之间有两次数据拷贝，一次是将用户空间的fd集合拷贝到内核空间，另一次是将就绪的fd集合拷贝回用户空间。这些拷贝操作会消耗一定的时间和内存。内核会将就绪的文件描述符对应的比特位保留为1，其他的置0，复制到用户空间。用户应用程序需要遍历设置的文件描述符集合以检查有哪些就绪事件。

select避免了非阻塞IO的那种无效轮询，为此付出的代价是一次select系统调用的阻塞，外加N次就绪文件描述符的系统调用。



#### 2.poll

```c++
int poll(struct pollfd *fds, nfds_t nfds, int timeout);

struct pollfd {
    int    fd;       /* file descriptor */
    short  events;   /* events to look for */
    short  revents;  /* events returned */
 };
```

`pollfd`由3部分组成，首先是描述符`fd`，其次`events`表示描述符`fd`上待检测的事件类型，一个`short`类型的数字用来表示多种事件，自然可以想到用的是二进制掩码的方式来进行位操作。

poll与select本质上没有太大的区别，区别如下：

1. poll会将每次遍历之后的结果保存到revents字段中，没有select那种值-结果参数，也就不需要每次调用poll的时候重置我们感兴趣的描述符以及相关事件。
2. 错误事件不能在events中进行设置，但是当相应事件发生时会通过revents字段返回。

3. poll函数将设置最大监听数量的权限给了程序设计者，自由控制pollfd结构数组的大小，突破了select函数1024个最大描述符的限制。



#### 3.epoll

```c++
int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);  
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
```

下面概括每个函数完成的工作：

epoll_create:

创建一个匿名文件，在当前进程中分配一个空闲的文件描述符与之绑定，在该文件描述符指向的file结构体的private_data字段指向一个eventpoll结构体。

至于为什么要使用文件描述符，是因为这样的话就可以递归监听eventpoll。

eventpoll结构体主要包含以下内容：

1. 匿名文件的file结构体指针
2. 等待在该eventpoll上的进程队列 wq
3. 就绪的文件描述符队列 rdllist
4. 红黑树根节点 rbr
5. 监听该eventpoll的eventpoll队列 poll_wait

epoll_create执行完后结构如下：

<img src="/Users/yv_zhanghao/Documents/MarkdownFiles/OperatingSystem/1.jpg">

epoll_ctl:

现在考虑使用epoll_ctl向eventpoll添加事件的过程。

第一步，首先将要监听的文件描述符封装到一个epitem结构体中，这个epitem就是eventpoll中红黑树的节点。初始化epitem包括初始化其中的eventpoll指针和目标文件描述符的file结构体指针。

第二步，设置回调函数。我们知道，每个socket其实都有一个等待队列，用于存储在该socket上等待的进程和回调函数。另外，linux高度抽象了文件的概念，每个文件描述符都有一个file_operations结构体，用于统一化各种文件操作。第二步就是调用文件的描述符上的poll操作，将ep_poll_callback设置为socket的回调函数。因此，只有实现了poll方法的文件描述符才可以被epoll监听。

第三步，将epitem插入红黑树。



epoll_wait

首先，检查eventpoll结构中的rdllist上有没有就绪的事件，如果有就直接将这个队列返回。

如果没有，那么就将自身线程加入到eventpoll的wq队列，设置回调函数default_wake_function，功能是将自身唤醒。

当socket上的事件就绪时，内核会通过ep_poll_callback中的ep_item找到eventpoll，将就绪事件加入rdllist，检查wq队列是否有线程阻塞。



epoll相比poll的优势是不用检查所有的文件描述符，内核直接返回了就绪的事件队列。同时，epoll支持边缘触发和水平触发两种模式，可以更好地满足应用程序的需求。

在 epoll 中，水平触发（Level-Triggered，LT）和边缘触发（Edge-Triggered，ET）的实现方式有所不同。

在水平触发模式下，当一个文件描述符上有数据可读或可写时，内核会不断通知应用程序，直到所有数据都被读取或写入。应用程序在接收到通知后，可以选择读取或写入任意数量的数据，而不必担心是否会丢失数据。

在 epoll 中，水平触发模式是默认模式。当应用程序调用 epoll_wait 等待事件时，如果文件描述符上有事件发生，内核会返回一个标志，表示该文件描述符上有事件可以处理。

而在边缘触发模式下，内核只在文件描述符状态发生变化时才会通知应用程序。当应用程序接收到通知后，必须立即读取或写入所有可用数据，否则数据会被丢失。

在 epoll 中，可以通过设置 EPOLLET 标志将文件描述符设置为边缘触发模式。当应用程序调用 epoll_wait 等待事件时，如果文件描述符上的事件未被处理，则会阻塞等待，直到有新的事件发生为止。在边缘触发模式下，应用程序必须处理所有可用数据，并确保在下一次读取或写入之前不会发生数据丢失。



### 4.信号驱动式IO

信号驱动IO不再用主动询问的方式去确认数据是否就绪，调用sigaction的安装一个SIGIO的信号处理函数，然后应用用户进程可以去做别的事，不用阻塞。当内核数据准备好后，再通过SIGIO信号通知应用进程，数据准备好后的可读状态。应用用户进程收到信号之后，立即调用recvfrom，去读取数据。

但是，由于信号是不可靠的，因此在使用信号驱动式 I/O 时需要考虑到信号可能会丢失的情况。

此外，IO过程仍然是同步阻塞的。



### 5.异步IO

异步 I/O 是一种 I/O 处理方式，它允许一个进程在等待 I/O 操作完成时继续执行其他任务，而不必阻塞等待 I/O 完成。异步 I/O 通过操作系统提供的通知机制，在 I/O 操作完成时通知进程，以实现异步处理。

1. 请求：异步 I/O 的请求由应用程序发起，通常包括描述符、缓冲区地址和数据长度等参数。在发起异步 I/O 请求后，应用程序可以继续执行其他任务。
2. 内核：内核负责将异步 I/O 请求提交到 I/O 队列中，并将请求相关的数据保存在内核中。当 I/O 操作完成时，内核会向应用程序发送通知，以便应用程序可以处理 I/O 操作的结果。
3. 通知机制：通知机制用于将 I/O 完成的事件通知给应用程序，以便应用程序可以及时处理 I/O 操作的结果。通知机制通常采用信号、回调函数或者事件通知等方式。



异步 I/O 和非阻塞 I/O 都是一种非阻塞的 I/O 处理方式，它们都允许应用程序在等待 I/O 完成时继续执行其他任务。但是，它们之间有几个主要的区别：

1. 实现方式：异步 I/O 由操作系统内核来处理 I/O 操作，并使用通知机制将 I/O 完成的事件通知给应用程序。而非阻塞 I/O 则需要应用程序在发起 I/O 请求后轮询检查 I/O 是否完成。
2. 接口：异步 I/O 通常使用操作系统提供的系统调用，如 aio_read() 和 aio_write() 等，应用程序发起 I/O 请求后可以立即返回。而非阻塞 I/O 则需要使用相应的系统调用，并将文件描述符设置为非阻塞模式，这样在进行 I/O 操作时可以立即返回。
3. 编程模型：异步 I/O 通常使用事件驱动编程模型，应用程序使用回调函数处理 I/O 完成的事件。而非阻塞 I/O 则需要应用程序自己实现轮询检查 I/O 完成的逻辑。





## 死锁形成的条件以及预防方法

死锁形成的4个必要条件：

1. 互斥访问
2. 持有并等待
3. 不可剥夺资源
4. 循环等待

对于死锁，有预防、避免和检测及接触方法。

### 1.死锁的预防

通过破坏4个条件中的任意一个来预防。

1. 互斥访问通常不可以破坏。
2. 持有并等待可以破坏。采用静态分配方式，一个进程在执行前需要申请全部的资源，如果不成功则全部释放。效率低。
3. 不可抢占不可以破坏。通常只有CPU是可抢占的。
4. 循环等待可以破坏。采用层次分配，将所有资源按层次编号，进程申请资源必须按照编号递增的方式申请，这样就不会出现循环等待的情况。效率低。

### 2.死锁的避免

银行家算法。核心思想就是在分配一个资源时，检查分配后是否会使得系统进入不安全的状态，如果会则拒绝分配。

不安全状态是指有可能发生死锁。

检查方法是在所有进程队列中，检查资源池中的资源是否能够满足其执行完成，如果可以，则假设该进程完成并释放资源，然后继续检查，直到所有进程执行完毕，则是安全状态，如果有进程无法执行完毕，则处于不安全状态。

### 3.死锁的检测

进程资源分配图。在分配图中，每个进程和资源都是一个节点，进程持有资源就是资源有一条边指向进程，进程申请资源就是进程有一条边指向资源。

死锁检测就是检查分配图：

1. 如果没有循环，则没有死锁。
2. 如果有循环，则不一定有死锁。需要进一步判断。对于不阻塞的进程，假设执行完毕，释放其资源，然后检查是否有新的不阻塞进程产生。这个过程有点像拓扑排序。如果最后能全部执行，则没有死锁，否则有死锁。

### 4.死锁的解除

1. **立即结束所有进程的执行，重新启动操作系统**：这种方法简单，但以前所在的工作全部作废，损失很大。
2. **撤销涉及死锁的所有进程，解除死锁后继续运行**：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。
3. **逐个撤销涉及死锁的进程，回收其资源直至死锁解除。**
4. **抢占资源**：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除。





## Linux系统中的各种栈

### 1.进程栈

进程栈是指主线程的用户态栈，是在fork时创建的，位于线程的虚拟地址空间中文件映射区的上方，增长方向是高地址向低地址增长。进程栈是动态增长的，可以触发缺页异常使操作系统映射更多的物理内存到栈空间。

### 2.线程栈

对于从主线程创建来的线程，他们与主线程共享同一个虚拟内存空间，所以他们各自的栈空间其实是主线程调用mmap在文件映射去分配的。每个线程栈都是固定大小的，不可以动态增长。

### 3.内核栈

每个线程都有一个task_struct，他们都有一个内核栈。当线程从用户态陷入内核态时，就要从它的用户态栈切换到内核栈。内核栈也是固定大小的，只有4个page的大小，因此默认就是16KB。内核栈也是从高地址向低地址增长，它的最低位置有一个thread_info结构体，存储了task的相关信息，它的最高位置有一个pt_regs结构体，存储了用户态的寄存器值。当线程从内核态返回用户态时，需要恢复这些寄存器上下文。

<img src="/Users/yv_zhanghao/Documents/MarkdownFiles/OperatingSystem/2.jpg">

### 4.中断栈

中断栈可能是单独分配的，也可能是复用进程的内核栈的。如果是单独分配的，那么每个处理器都有一个单独的中断栈。

CPU收到中断信号后会首先保存被中断程序的状态，然后再去执行中断处理程序，最后再返回到原程序中被中断的点去执行。具体是怎么做呢？我们以x86为例讲解一下。

CPU收到中断信号后会首先把一些数据push到内核栈上，保存的数据是和当前执行点相关的，这样中断完成后就可以返回到原执行点。如果CPU当前处于用户态，则会先切换到内核态，把用户栈切换为内核栈再去保存数据(内核栈的位置是在当前线程的TSS中获取的)。CPU都push了哪些数据呢？分为两种情况。当CPU处于内核态时，会push寄存器EFLAGS、CS、EIP的值到栈上，对于有些CPU异常还会push Error Code。Push CS、EIP是为了中断完成后返回到原执行点，push EFLAGS是为了恢复之前的CPU状态。当CPU处于用户态时，会先切换到内核态，把栈切换到内核栈，然后push寄存器SS(old)、ESP(old)、EFLAGS、CS、EIP的值到新的内核栈，对于有些CPU异常还会push Error Code。Push SS(old)、ESP(old)，是为了中断返回的时候可以切换回原来的栈。有些CPU异常会push Error Code，这样可以方便中断处理程序知道更具体的异常信息。

保存完被中断程序的信息之后，就要去执行中断处理程序了。CPU会根据当前中断信号的向量号去查询中断向量表找到中断处理程序。CPU是如何获得当前中断信号的向量号的呢，如果是CPU异常可以在CPU内部获取，如果是指令中断，在指令中就有向量号，如果是硬件中断，则可以从中断控制器中获取中断向量号。那CPU又是怎么找到中断向量表呢，是通过IDTR寄存器。

CPU现在已经把被中断的程序现场保存到内核栈上了，又得到了中断向量号，然后就根据中断向量号从中断向量表中找到对应的门描述符，对描述符做一番安全检查之后，CPU就开始执行中断处理函数(就是门描述符中的段偏移)。中断处理函数的最末尾执行IRET指令，这个指令会根据前面保存在栈上的数据跳回到原来的指令继续执行。

 





## Redis数据结构

Redis 提供了丰富的数据类型，常见的有五种数据类型：**String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）**。

随着 Redis 版本的更新，后面又支持了四种数据类型： **BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）**。 Redis 五种数据类型的应用场景：

- String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。
- List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。
- Hash 类型：缓存对象、购物车等。
- Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
- Zset 类型：排序场景，比如排行榜、电话和姓名排序等。

Redis 后续版本又支持四种数据类型，它们的应用场景如下：

- BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
- GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。



### String

String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）。 SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串：

- **SDS 不仅可以保存文本数据，还可以保存二进制数据**。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。
- **SDS 获取字符串长度的时间复杂度是 O(1)**。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。
- **Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出**。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。

应用场景：

1. 缓存对象：可以直接缓存整个对象的JSON，也可以分字段缓存
2. 常规计数：因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等
3. 分布式锁：SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁，EX/PX加过期时间兜底。value要有客户端的唯一标识。解锁时要判断是自己加的锁才能释放，通过lua脚本实现原子性。
4. 共享Session信息。分布式系统下借助Redis统一存储Session信息。



### List

List 类型的底层数据结构是由**双向链表或压缩列表**实现的：

- 如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用**压缩列表**作为 List 类型的底层数据结构；
- 如果列表的元素不满足上面的条件，Redis 会使用**双向链表**作为 List 类型的底层数据结构；

但是**在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表**。

应用场景：

1. 消息队列。消息队列在存取消息时，必须要满足三个需求，分别是**消息保序、处理重复的消息和保证消息可靠性**。

Redis 的 List 和 Stream 两种数据类型，就可以满足消息队列的这三个需求。我们先来了解下基于 List 的消息队列实现方法，后面在介绍 Stream 数据类型时候，在详细说说 Stream。

*1、如何满足消息保序需求？*

List 可以使用 LPUSH + RPOP （或者反过来，RPUSH+LPOP）命令实现消息队列。

在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 `RPOP` 命令（比如使用一个while(1)循环）。如果有新消息写入，RPOP命令就会返回结果，否则，RPOP命令返回空值，再继续循环。所以，即使没有新消息写入List，消费者也要不停地调用 RPOP 命令，这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。为了解决这个问题，Redis提供了 BRPOP 命令。**BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据**。和消费者程序自己不停地调用RPOP命令相比，这种方式能节省CPU开销。

*2、如何处理重复的消息？*

消费者要实现重复消息的判断，需要 2 个方面的要求：

- 每个消息都有一个全局的 ID。
- 消费者要记录已经处理过的消息的 ID。当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。

**List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID。**

*3、如何保证消息可靠性？*

当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。

为了留存消息，List 类型提供了 `BRPOPLPUSH` 命令，这个命令的**作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存**。

List实现消息队列的缺点：不支持多个消费者消费同一条消息，也不支持消息组。Redis5.0提供的Stream数据类型可以支持。



### Hash

Hash 类型的底层数据结构是由**压缩列表或哈希表**实现的：

- 如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用**压缩列表**作为 Hash 类型的底层数据结构；
- 如果哈希类型元素不满足上面条件，Redis 会使用**哈希表**作为 Hash 类型的底层数据结构。

**在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了**。

应用场景：

1. 存储对象：Hash 类型的 （key，field， value） 的结构与对象的（对象id， 属性， 值）的结构相似，也可以用来存储对象。

在介绍 String 类型的应用场景时有所介绍，String + Json也是存储对象的一种方式，那么存储对象时，到底用 String + json 还是用 Hash 呢？

一般对象用 String + Json 存储，对象中某些频繁变化的属性可以考虑抽出来用 Hash 类型存储。

以购物车为例，这是一个需要频繁变化的对象，可以使用Hash来缓存。

以用户 id 为 key，商品 id 为 field，商品数量为 value。当前仅仅是将商品ID存储到了Redis 中，在回显商品具体信息的时候，还需要拿着商品 id 查询一次数据库，获取完整的商品的信息。




### Set

Set 类型的底层数据结构是由**哈希表或整数集合**实现的：

- 如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用**整数集合**作为 Set 类型的底层数据结构；
- 如果集合中的元素不满足上面条件，则 Redis 使用**哈希表**作为 Set 类型的底层数据结构。

集合的主要几个特性，无序、不可重复、支持并交差等操作。这里有一个潜在的风险。**Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞**。在主从集群中，为了避免主库因为 Set 做聚合计算（交集、差集、并集）时导致主库被阻塞，我们可以选择一个从库完成聚合统计，或者把数据返回给客户端，由客户端来完成聚合统计。

应用场景：

1. 点赞。Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章id，value 是用户id。
2. 共同关注。Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。key 可以是用户id，value 则是已关注的公众号的id。则可以通过交集运算获得共同关注。
3. 抽奖活动。存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。



### Zset

Zset 类型的底层数据结构是由**压缩列表或跳表**实现的：

- 如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用**压缩列表**作为 Zset 类型的底层数据结构；
- 如果有序集合的元素不满足上面的条件，Redis 会使用**跳表**作为 Zset 类型的底层数据结构；

**在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。**

应用场景：

1. 排行榜。有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。
2. 姓名、电话字典序排序。使用有序集合的 `ZRANGEBYLEX` 或 `ZREVRANGEBYLEX` 可以帮助我们实现电话号码或姓名的排序，我们以 `ZRANGEBYLEX` （返回指定成员区间内的成员，按 key 正序排列，分数必须相同）为例。注意，使用字典序排序的有序集合各个元素的score需要相同。



### BitMap

Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行`0|1`的设置，表示某个元素的值或者状态，时间复杂度为O(1)。

Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。

应用场景：

1. 签到统计。
2. 判断用户登录状态。



### HyperLogLog

HyperLogLog 是一种用于「统计基数」的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。

所以，简单来说 HyperLogLog **提供不精确的去重计数**。

应用场景：

百万级网页UV计数。

在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。

```shell
PFADD page1:uv user1 user2 user3 user4 user5
```

接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。

```shell
PFCOUNT page1:uv
```



### GEO

主要用于存储地理位置信息，并对存储的信息进行操作。

GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。

应用场景：

1. 滴滴叫车。





### Stream

Redis 专门为消息队列设计的数据类型。

用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。

Stream 消息队列操作命令：

- XADD：插入消息，保证有序，可以自动生成全局唯一 ID；
- XLEN ：查询消息长度；
- XREAD：用于读取消息，可以按 ID 读取数据；
- XDEL ： 根据消息 ID 删除消息；
- DEL ：删除整个 Stream；
- XRANGE ：读取区间消息
- XREADGROUP：按消费组形式读取消息；
- XPENDING 和 XACK：
    - XPENDING 命令可以用来查询每个消费组内所有消费者「已读取、但尚未确认」的消息；
    - XACK 命令用于向消息队列确认消息处理已完成；

Stream 可以以使用 **XGROUP 创建消费组**，创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。

创建两个消费组，这两个消费组消费的消息队列是 mymq，都指定从第一条消息开始读取：

```shell
# 创建一个名为 group1 的消费组，0-0 表示从第一条消息开始读取。
> XGROUP CREATE mymq group1 0-0
OK
# 创建一个名为 group2 的消费组，0-0 表示从第一条消息开始读取。
> XGROUP CREATE mymq group2 0-0
OK
```

消费组 group1 内的消费者 consumer1 从 mymq 消息队列中读取所有消息的命令如下：

```shell
# 命令最后的参数“>”，表示从第一条尚未被消费的消息开始读取。
> XREADGROUP GROUP group1 consumer1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1654254953808-0"
         2) 1) "name"
            2) "xiaolin"
```

**消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了，即同一个消费组里的消费者不能消费同一条消息**。

Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。

如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，**消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息**。



Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？

一个专业的消息队列，必须要做到两大块：

- 消息不丢。但是Redis 消息中间件可能会丢失信息。Redis 在以下 2 个场景下，都会导致数据丢失：
    - AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能。
    - 主从复制也是异步的，主从切换时，也存在丢失数据的可能。
- 消息可堆积。但是Redis指定队列最大长度时，队列长度超过上限后，旧消息会被删除，只保留固定长度的新消息。这么来看，Stream 在消息积压时，如果指定了最大长度，还是有可能丢失消息的。但 Kafka、RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上，当消息积压时，无非就是多占用一些磁盘空间。



补充：Redis 发布/订阅机制为什么不可以作为消息队列？

发布订阅机制存在以下缺点，都是跟丢失数据有关：

1. 发布/订阅机制没有基于任何数据类型实现，所以不具备「数据持久化」的能力，也就是发布/订阅机制的相关操作，不会写入到 RDB 和 AOF 中，当 Redis 宕机重启，发布/订阅机制的数据也会全部丢失。
2. 发布订阅模式是“发后既忘”的工作模式，如果有订阅者离线重连之后不能消费之前的历史消息。
3. 当消费端有一定的消息积压时，也就是生产者发送的消息，消费者消费不过来时，如果超过 32M 或者是 60s 内持续保持在 8M 以上，消费端会被强行断开，这个参数是在配置文件中设置的，默认值是 `client-output-buffer-limit pubsub 32mb 8mb 60`。

所以，发布/订阅机制只适合即时通讯的场景，比如构建哨兵集群的场景采用了发布/订阅机制。



## Redis的持久化方式

### 1.AOF持久化 (Append Only File)

AOF 日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里。

#### AOF日志没有采取数据库常用的WAL(Write Ahead Logging)技术，它先执行命令，再写AOF日志。原因如下：

1. Redis在写日志前没有语法检查，先写日志的话会写入错误命令。
2. WAL技术的优势是记录了redolog之后，可以先不执行命令，而是之后异步执行，从而提高效率，而且能够通过redolog保证事务的持久性。但是Redis是以轻量和高效为特点的，它基于内存，执行命令的速度本身就很快，完全没必要异步执行，而且Redis是弱事务，如果追求强事务的话可以使用MySQL等数据库。



#### AOF日志的写入过程：

1. 主线程先执行命令
2. 主线程将命令写入aof_buf
3. 主线程调用write将aof_buf中的命令文本写入AOF文件的内核缓冲区
4. 之后行为有3种，Redis 提供了 3 种写回硬盘的策略。
    1. **appendfsync always**，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘，也就是主线程每次write后都追加fsync操作，后台线程执行fsync后主线程才返回，这种策略对性能影响最高。
    2. **appendfsync everysec**，这个单词的意思是每秒，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后主线程就可以返回，每隔大概1s会在write后追加fsync操作，对主线程的性能影响较低。
    3. **appendfsync no**，意味着不由 Redis 控制写回硬盘的时机，刷盘时机由操作系统决定，对主线程性能影响最低。



#### AOF日志过大触发AOF重写

AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。

所以，Redis 为了避免 AOF 文件越写越大，提供了 **AOF 重写机制**，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。

AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。在使用重写机制后会丢弃历史命令，一个键值对在重写日志中只用一条命令就行了。

Redis 的**重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的**，这么做可以达到两个好处：

- 子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；
- 子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。

触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。

**但是重写过程中，主进程依然可以正常处理命令**，那问题来了，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，那么会发生写时复制，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？

为了解决这种数据不一致问题，Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。

在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。

也就是说，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:

- 执行客户端发来的命令；
- 将执行后的写命令追加到 「AOF 缓冲区」；
- 将执行后的写命令追加到 「AOF 重写缓冲区」；

当子进程完成 AOF 重写工作（*扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志*）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。

主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：

- 将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；
- 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。

信号函数执行完后，主进程就可以继续像往常一样处理命令了。



### 2.RDB持久化 (Redis Database)

因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢。为了解决这个问题，Redis 增加了 RDB 快照。RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：

- 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；
- 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以**避免主线程的阻塞**；

执行 bgsave 过程中，Redis 依然**可以继续处理操作命令**的，也就是数据是能被修改的，关键的技术就在于**写时复制技术（Copy-On-Write, COW）。**

执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。





### 3.混合持久化

RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。

AOF 优点是丢失数据少，但是数据恢复不快。

为了集成了两者的优点， Redis 4.0 提出了**混合使用 AOF 日志和内存快照**，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。

混合持久化工作在 **AOF 日志重写过程**，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。

也就是说，使用了混合持久化，AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。





## Redis的过期删除策略

每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。

Redis采用 **惰性删除** + **定期删除**。

惰性删除策略的做法是，**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**

定期删除策略的做法是，**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**



### Redis 持久化时，对过期键会如何处理的？分为RDB持久化和AOF持久化。

RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。

- **RDB 文件生成阶段**：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，**过期的键「不会」被保存到新的 RDB 文件中**，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。

- RDB 加载阶段

    ：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况：

    - **如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中**。所以过期键不会对载入 RDB 文件的主服务器造成影响；
    - **如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中**。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。

AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。

- **AOF 文件写入阶段**：当 Redis 以 AOF 模式持久化时，**如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值**。
- **AOF 重写阶段**：执行 AOF 重写时，会对 Redis 中的键值对进行检查，**已过期的键不会被保存到重写后的 AOF 文件中**，因此不会对 AOF 重写造成任何影响。



### Redis 主从模式中，对过期键会如何处理？

当 Redis 运行在主从模式下时，**从库不会进行过期扫描，从库对过期的处理是被动的**。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。

从库的过期键处理依靠主服务器控制，**主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库**，从库通过执行这条 del 指令来删除过期的 key。



## Redis 内存满了，会发生什么？

在 Redis 的运行内存达到了某个阀值，就会触发**内存淘汰机制**，这个阀值就是我们设置的最大运行内存，此值在 Redis 的配置文件中可以找到，配置项为 maxmemory。



### Redis 内存淘汰策略有哪些？

Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。

***1、不进行数据淘汰的策略***

**noeviction**（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。

***2、进行数据淘汰的策略***

针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。 在设置了过期时间的数据中进行淘汰：

- **volatile-random**：随机淘汰设置了过期时间的任意键值；
- **volatile-ttl**：优先淘汰更早过期的键值。
- **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
- **volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；

在所有数据范围内进行淘汰：

- **allkeys-random**：随机淘汰任意键值;
- **allkeys-lru**：淘汰整个键值中最久未使用的键值；
- **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

 

### Redis的内存淘汰策略中LRU和LFU分别是如何实现的？

Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**。

当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。

Redis 实现的 LRU 算法的优点：

- 不用为所有的数据维护一个大链表，节省了空间占用；
- 不用在每次数据访问时都移动链表项，提升了缓存的性能；

但是 LRU 算法有一个问题，**无法解决缓存污染问题**，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。

因此，在 Redis 4.0 之后引入了 LFU 算法来解决这个问题。

LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。Redis 对象的结构如下：

```c
typedef struct redisObject {
    ...
      
    // 24 bits，用于记录对象的访问信息
    unsigned lru:24;  
    ...
} robj;
```

Redis 对象头中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。

**在 LRU 算法中**，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。

**在 LFU 算法中**，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，用来记录 key 的访问时间戳；低 8bit 存储 logc(Logistic Counter)，用来记录 key 的访问频次。





## Redis缓存设计

### 如何避免缓存穿透、缓存雪崩和缓存击穿？

**缓存穿透**是指客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。那么当有大量这样的请求到来时，数据库的压力骤增。这就是缓存穿透问题。

解决方案：

1. 加强数据格式校验，避免非法请求
2. 缓存空对象。可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。
3. 布隆过滤。使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。



**缓存雪崩** 是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。

解决方法：

1. 给不同的Key的TTL添加随机值，或者对某些key设置不过期。避免短时间内大量key过期失效。
2. 利用Redis集群提高服务的可用性。
3. 给缓存业务添加降级限流策略。
4. 给业务添加多级缓存。



**缓存击穿** 也叫热点Key问题，就是一个被高井发访问井且缓存重建业务较复杂的key突然失效了，无数的请来访问会在瞬间给数据库带来巨大的冲击。

解决方案：

1. 互斥锁+逻辑过期，互斥锁保证同一时间只有一个业务线访问数据库重建缓存。逻辑过期能够使得未获得互斥锁的请求返回旧值或默认值。
2. 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；



### 如何设计一个缓存策略，可以动态缓存热点数据呢？

由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而**只是将其中一部分热点数据缓存起来**，所以我们要设计一个热点数据动态缓存的策略。

热点数据动态缓存的策略总体思路：**通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据**。

以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：

- 先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；
- 同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；
- 这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。

在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。



## 常见的缓存更新策略

### Cache Aside

Cache Aside（旁路缓存）策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。

**写策略的步骤：**

- 先更新数据库中的数据，再删除缓存中的数据。

**读策略的步骤：**

- 如果读取的数据命中了缓存，则直接返回数据；
- 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。

注意，写策略的步骤的顺序不能倒过来，即**不能先删除缓存再更新数据库**，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。

**Cache Aside 策略适合读多写少的场景，不适合写多的场景**，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果业务对缓存命中率有严格的要求，那么可以考虑两种解决方案



### Read/Write Through

Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。



### Write Back

Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。实际上，Write Back（写回）策略也不能应用到我们常用的数据库和缓存的场景中，因为 Redis 并没有异步更新数据库的功能。Write Back 是计算机体系结构中的设计，比如 CPU 的缓存、操作系统中文件系统的缓存都采用了 Write Back（写回）策略。

**Write Back 策略特别适合写多的场景**，因为发生写操作的时候， 只需要更新缓存，就立马返回了。比如，写文件的时候，实际上是写入到文件系统的缓存就返回了，并不会写磁盘。

**但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险**，因为缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电，就会造成原本缓存中的脏数据丢失。所以你会发现系统在掉电之后，之前写入的文件会有部分丢失，就是因为 Page Cache 还没有来得及刷盘造成的。





### 如何保证数据库和缓存的一致性？

最常使用的Cache Aside粗略，在更新数据时，先更新数据库，再删除缓存。由于缓存操作速度很快，所以这种方式发生并发问题的概率很小。但仍然有概率发生并发问题，所以需要为缓存设置过期时间兜底。

另外删除缓存还是更新缓存取决于系统的读和写操作的频率。如果读操作多，那么可以采用更新缓存，如果写操作多，那么可以采用删除缓存，以避免大量无效的写操作。

最后，更新数据库和缓存是两个不同的操作，如果第二个操作失败的话，会引起不一致。所以需要保证两个操作的原子性。有以下方案：

1. 单体系统，则将两个操作放入一个事务，分布式系统则利用TCC等分布式事务方案。
2. 重试机制。可以引入**消息队列**，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。
    - 如果应用**删除缓存失败**，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是**重试机制**。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
    - 如果**删除缓存成功**，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。
3. 订阅 MySQL binlog，再操作缓存。我们可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。





## Redis实现延迟队列

延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：

- 在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；
- 打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；
- 点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；

在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。

使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。

另外，redis默认是按照score从小到大排序的，如果要取最大的值，可以使用 zrevrange 命令。



## Redis大Key

大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。

一般而言，下面这两种情况被称为大 key：

- String 类型的值大于 10 KB；
- Hash、List、Set、ZSet 类型的元素的个数超过 5000个；

### 大Key会造成什么问题？

大 key 会带来以下四种影响：

- **客户端超时阻塞**。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
- **引发网络阻塞**。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
- **阻塞工作线程**。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
- **内存分布不均**。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。

### 如何查找大Key？

***1、redis-cli --bigkeys 查找大key***

***2、使用 SCAN 命令查找大 key***

***3、使用 RdbTools 工具查找大 key***

RdbTools 是第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。



### 如何删除大Key？

***1、分批次删除***

例如对于**删除大 Hash**，可以使用 `hscan` 命令，每次获取 100 个字段，再用 `hdel` 命令，每次删除 1 个字段。

***2、异步删除***

从 Redis 4.0 版本开始，可以采用**异步删除**法，**用 unlink 命令代替 del 来删除**。

这样 Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。

除了主动调用 unlink 命令实现异步删除之外，我们还可以通过配置参数，达到某些条件的时候自动进行异步删除。





## Redis 管道

管道技术（Pipeline）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。

普通命令模式客户端每次向服务器发送一个命令，并等待服务器返回响应。

管道模式中，客户端会一次性向服务器发送一批命令，服务器会响应这一批命令的结果。

要注意的是，管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能。





## Redis 事务

Redis支持弱事务。通过multi、exec、discard和watch这四个命令来完成的。

具体过程是：

1. 执行 watch key 监控事务中要操作的字段
2. 执行 multi 开启事务
3. 写入具体的业务操作
4. 执行 exec 并返回执行结果

首先 watch 监控 key 所起的作用实际上是一个乐观锁，它所监控的是在事务加入到队列期间有没有其他客户端对所监控的值进行修改，通过REDIS_DIRTY_CAS作为标志位，如果key对应的值被其他客户端修改了则开启REDIS_DIRTY_CAS，如果没有被修改则不开启REDIS_DIRTY_CAS。

然后 multi 的作用是开启事务，如果执行了 multi 则表示开启事务，那么接下来发送到客户端的命令不会立即执行，而是被加入到一个FIFO的队列中，直到遇到 exec 命令，则队列中的命令会依次执行并根据先进先出的顺序返回执行结果。

执行 exec 命令时，首先会判断REDIS_DIRTY_CAS是否开启，如果开启，说明该事务关注的key的值在添加命令到队列中期间已经被其他客户端修改过了，这时就不会再执行事务队列中的命令而是会返回（nil），如果REDIS_DIRTY_CAS没有开启，说明在执行事务期间key没有被修改，则继续执行事务队列并返回执行结果。还有一点，一个watch对应的是一个事务，也就是说监控只持续到exec命令，再开启一个事务时需要提前再次设置watch。

因此可以总结如下：

1. 原子性：Redis事务只保证事务中的命令同执行或同不执行，一旦开始执行不保证同成功同失败，也就是其中一条命令失败并不会回滚之前的命令。Redis选择不执行事务中的命令的原因可能有：watch监控的key被其他客户端修改了；命令队列中存在语法错误的命令。
2. 隔离性：事务之间是具备隔离性的，一个事务执行期间不会执行其他客户端提交的命令。
3. 持久性：Redis事务的持久性是由Redis的持久化策略决定的，包括AOF持久化、RDB持久化和混合持久化。他们不保证完全的安全性。
4. 一致性：单机可以，但集群中不能保证实时一致性。





## Redis 实现分布式锁

Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。

Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：

- 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
- 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。

- 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；
- 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX (EX的单位是秒，PX的单位是毫秒)选项，设置其过期时间；
- 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；

满足这三个条件的分布式命令如下：

```c
SET lock_key unique_value NX PX 10000 
```

- lock_key 就是 key 键；
- unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；
- NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
- PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。

而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。

可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。

```c
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。



## Redis 主从复制架构

要避免这种单点故障，最好的办法是将数据备份到其他服务器上，让这些服务器也可以对外提供服务，这样即使有一台服务器出现了故障，其他服务器依然可以继续提供服务。

多台服务器要保存同一份数据，这里问题就来了。

这些服务器之间的数据如何保持一致性呢？数据的读写操作是否每台服务器都可以处理？

Redis 提供了**主从复制模式**，来避免上述的问题。

这个模式可以保证多台服务器的数据一致性，且主从服务器之间采用的是「读写分离」的方式。

主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。

### 1. 第一次同步

多台服务器之间要通过什么方式来确定谁是主服务器，或者谁是从服务器呢？

我们可以使用 `replicaof`（Redis 5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系。

比如，现在有服务器 A 和 服务器 B，我们在服务器 B 上执行下面这条命令：

```text
# 服务器 B 执行这条命令
replicaof <服务器 A 的 IP 地址> <服务器 A 的 Redis 端口号>
```

接着，服务器 B 就会变成服务器 A 的「从服务器」，然后与主服务器进行第一次同步。

主从服务器间的第一次同步的过程可分为三个阶段：

- 第一阶段是建立链接、协商同步；
- 第二阶段是主服务器同步数据给从服务器；这是通过RDB快照片实现的。主服务器生成一个RDB快照发送给从服务器，并将开始生成快照那一刻之后的写操作写入replication buffer中。从服务器用快照进行初始化。
- 第三阶段是主服务器发送新写操作命令给从服务器。主服务器将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，从服务器执行来自主服务器 replication buffer 缓冲区里发来的命令，这时主从服务器的数据就一致了。

<img src="/Users/yv_zhanghao/Documents/MarkdownFiles/Redis/1.jpg">



### 2. 命令传播

主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。

后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。

而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。

上面的这个过程被称为**基于长连接的命令传播**，通过这种方式来保证第一次同步后的主从服务器的数据一致性。



### 3. 分摊主服务器的压力

在前面的分析中，我们可以知道主从服务器在第一次数据同步的过程中，主服务器会做两件耗时的操作：生成 RDB 文件和传输 RDB 文件。

主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题：

- 虽然主服务器是通过 bgsave 命令来生成 RDB 文件的，备份操作本身不会阻塞主线程，但是主服务器仍然会忙于使用 fork() 创建子进程，如果主服务器的内存数据非大，在执行 fork() 函数时是会阻塞主线程的，从而使得 Redis 无法正常处理请求；
- 传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响。

为了解决这个问题，Redis 支持从服务器有自己的从服务器，我们可以把拥有从服务器的从服务器当作经理角色，它不仅可以接收主服务器的同步数据，自己也可以同时作为主服务器的形式将数据同步给从服务器，最终形成一个树结构。





### 4.增量复制

主从服务器在完成第一次同步后，就会基于长连接进行命令传播。

可是，网络总是不按套路出牌的嘛，说延迟就延迟，说断开就断开。

如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。

那么问题来了，如果此时断开的网络，又恢复正常了，要怎么继续保证主从服务器的数据一致性呢？

在 Redis 2.8 之前，如果主从服务器在命令同步时出现了网络断开又恢复的情况，从服务器就会和主服务器重新进行一次全量复制，很明显这样的开销太大了，必须要改进一波。

所以，从 Redis 2.8 开始，网络断开又恢复后，从主从服务器会采用**增量复制**的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。

**那么增量复制是如何实现的呢？**

在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。这是一个环形缓冲区，主服务器写数据，从服务器读数据。

当网络恢复后，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，也就是写数据和读数据的偏移量之间的差距，然后来决定对从服务器执行哪种同步操作：

- 如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**增量同步**的方式；
- 相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**全量同步**的方式。



### 总结

主从复制共有三种模式：**全量复制、基于长连接的命令传播、增量复制**。

主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。

第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。

如果遇到网络断开，增量复制就可以上场了，不过这个还跟 repl_backlog_size 这个大小有关系。

如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。





### 怎么判断 Redis 某个节点是否正常工作？

Redis 判断节点是否正常工作，基本都是通过互相的 ping-pong 心态检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。

Redis 主从节点发送的心态间隔是不一样的，而且作用也有一点区别：

- Redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态，可通过参数repl-ping-slave-period控制发送频率。

- Redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了：

    - 实时监测主从节点网络状态；
    - 上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。

    

### 主从复制架构中，过期key如何处理？

主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。



### Redis 是同步复制还是异步复制？

Redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。





### 主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？

replication buffer 、repl backlog buffer 区别如下：

- 出现的阶段和功能不一样：
    - repl backlog buffer 是在增量复制阶段出现，**一个主节点只分配一个 repl backlog buffer**，主要用于从节点从中读取需要同步的命令。
    - replication buffer 是在全量复制阶段出现，**主节点会给每个新连接的从节点，分配一个 replication buffer**，主要用于缓存主节点向从节点发送RDB快照期间新增的写命令。
- 这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：
    - 当 repl backlog buffer 满了，因为是环形结构，会直接**覆盖起始位置数据**;
    - 当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，**重新开始全量复制**。



### 主从不一致性

主从数据不一致，就是指客户端从从节点中读取到的值和主节点中的最新值并不一致。

之所以会出现主从数据不一致的现象，是**因为主从节点间的命令复制是异步进行的**，所以无法实现强一致性保证（主从数据时时刻刻保持一致）。

具体来说，在主从节点命令传播阶段，主节点收到新的写命令后，会发送给从节点。但是，主节点并不会等到从节点实际执行完命令后，再把结果返回给客户端，而是主节点自己在本地执行完命令后，就会向客户端返回结果了。如果从节点还没有执行主节点同步过来的命令，主从节点间的数据就不一致了。

那么如何应对主从不一致性？

第一种方法，尽量保证主从节点间的网络连接状况良好。

第二种方法，可以开发一个外部程序来监控主从节点间的复制进度，当复制进度大于某个阈值，可以暂停从该从服务器读取缓存。具体做法：

- Redis 的 INFO replication 命令可以查看主节点接收写命令的进度信息（master_repl_offset）和从节点复制写命令的进度信息（slave_repl_offset），所以，我们就可以开发一个监控程序，先用 INFO replication 命令查到主、从节点的进度，然后，我们用 master_repl_offset 减去 slave_repl_offset，这样就能得到从节点和主节点间的复制进度差值了。
- 如果某个从节点的进度差值大于我们预设的阈值，我们可以让客户端不再和这个从节点连接进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从节点都不能连接的情况，我们需要把复制进度差值的阈值设置得大一些。



### 主从复制和主从切换如何减少数据丢失？

对于主从复制，总结为降级服务。

对于 Redis 主节点与从节点之间的数据复制，是异步复制的，当客户端发送写请求给主节点的时候，客户端会返回 ok，接着主节点将写请求异步同步给各个从节点，但是如果此时主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。

Redis 配置里有一个参数 min-slaves-max-lag，表示一旦所有的从节点数据复制和同步的延迟都超过了 min-slaves-max-lag 定义的值，那么主节点就会拒绝接收任何请求。

假设将 min-slaves-max-lag 配置为 10s 后，根据目前 master->slave 的复制速度，如果数据同步完成所需要时间超过10s，就会认为 master 未来宕机后损失的数据会很多，master 就拒绝写入新请求。这样就能将 master 和 slave 数据差控制在10s内，即使 master 宕机也只是这未复制的 10s 数据。

那么对于客户端，当客户端发现 master 不可写后，我们可以采取降级措施，将数据暂时写入本地缓存和磁盘中，在一段时间（等 master 恢复正常）后重新写入 master 来保证数据不丢失，也可以将数据写入 kafka 消息队列，等 master 恢复正常，再隔一段时间去消费 kafka 中的数据，让将数据重新写入 master 。

对于主从切换，也是降级服务，具体如下：

先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？

在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。

如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。

这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在从节点中选举出一个 leeder 作为主节点，这时集群就有两个主节点了 —— **脑裂出现了**。

这时候网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，**因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题**。

总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。



总结：当主节点发现「从节点下线的数量太多」，或者「网络延迟太大」的时候，那么主节点会禁止写操作，直接把错误返回给客户端。与此同时，哨兵会发现主节点下线，会选取新主节点，等到旧主节点上线后降为从节点，也不会丢失太多数据。





## Redis 的哨兵架构

Redis 在 2.8 版本以后提供的**哨兵（*Sentinel*）机制**，它的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些“动作”，来修复异常状态。

哨兵节点主要负责三件事情：**监控、选主、故障转移**。

### 哨兵监控

哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「**主观下线**」。这个「规定的时间」是配置项 `down-after-milliseconds` 参数设定的，单位是毫秒。

除了主观下线，还有**客观下线**的概念。客观下线只针对主节点。当哨兵不能及时收到主节点的响应时，有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。所以，为了减少误判的情况，我们通常使用多个节点部署成**哨兵集群**（*最少需要三台机器来部署哨兵集群*），**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**。

具体的，当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。quorum 的值一般设置为哨兵个数的二分之一加 1。

<img src="/Users/yv_zhanghao/Documents/MarkdownFiles/Redis/2.jpg">

### 哨兵选主

当哨兵监控到主节点下线并通过投票认定其客观下线后，就需要开始选主。由于判断出主节点客观下线的哨兵可能有多个，所以要选择一个哨兵作为leader来执行故障转移。

这是一个投票选举过程。该投票的候选者就是那些判断主节点客观下线的哨兵。候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。

那么在投票过程中，任何一个「候选者」，要满足两个条件，即可成为leader。

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

综上，**quorum 的值建议设置为哨兵个数的二分之一加 1**，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且**哨兵节点的数量应该是奇数**。



### 哨兵故障转移

在哨兵集群中通过投票的方式，选举出了哨兵 leader 后，就可以进行主从故障转移的过程了，如下图：

主从故障转移操作包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。
- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；



#### 步骤一：选出新主节点

第一步要做的就是在已下线主节点属下的所有「从节点」中，挑选出一个状态良好、数据完整的从节点，然后向这个「从节点」发送 SLAVEOF no one 命令，将这个「从节点」转换为「主节点」。

选择新主节点有两步，首先过滤掉网络连接不好的节点，其次通过三轮考察选择新主节点。

过滤网络连接不好的节点是通过主从节点断连次数来判断的，如果发生断连的次数超过了 10 次，就说明这个从节点的网络状况不好，不适合作为新主节点。

三轮考察：

- 第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前，
- 第二轮考察：如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。（具体指repl_backlog_buffer的读取位置）
- 第三轮考察：如果优先级和下标都相同，就选择从节点 ID 较小的那个。

### 步骤二：将从节点指向新主节点

当新主节点出现之后，哨兵 leader 下一步要做的就是，让已下线主节点属下的所有「从节点」指向「新主节点」，这一动作可以通过向「从节点」发送 `SLAVEOF` 命令来实现。

### 步骤三：通知客户端新主节点的地址

这主要**通过 Redis 的发布者/订阅者机制来实现**的。每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息。

客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。主从切换完成后，哨兵就会向 `+switch-master` 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了。

### 步骤四：将旧主节点设置为从节点

最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 `SLAVEOF` 命令，让它成为新主节点的从节点。



### 哨兵集群是如何组成的？

前面提到了 Redis 的发布者/订阅者机制，那就不得不提一下哨兵集群的组成方式，因为它也用到了这个技术。

在配置哨兵的信息时，只需要填下面这几个参数，设置主节点名字、主节点的 IP 地址和端口号以及 quorum 值。

```c
sentinel monitor <master-name> <ip> <redis-port> <quorum> 
```

不需要填其他哨兵节点的信息，那么它们是如何感知对方的，又是如何组成哨兵集群的？

在主从集群中，主节点上有一个名为`__sentinel__:hello`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

另外，主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。

总结：正是通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。





## Redis 的集群架构

Redis的主从复制和哨兵模式可以提供很好的分布式服务，但对于高并发场景下，一个主节点对于大量的写操作仍有点力不从心。因此，Redis提供了去中心化的集群架构。集群模式最小需要有6个节点，3主3从，主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。由于Redis的集群模式是去中心化的，所以可以水平扩展，即赠加新的节点。增加新节点只需要已经有的节点将一部分槽位转移给新节点即可。

### 分片存储

Redis Cluster 将所有数据划分为 16384 个 slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中。
当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地。这样当客户端要查找某个 key 时，可以直接定位到目标节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。

### 槽为定位算法

Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。
HASH_SLOT = CRC16(key) mod 16384

然后，客户端根据集群的槽位配置信息和得到的槽位，访问负责该key的节点。

### 跳转重定位

当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。客户端收到指令后除了跳转到正确的节点上去操作，还会同步更新纠正本地的槽位映射表缓存，后续所有 key 将使用新的槽位映射表。

### 选举原理

当某个slave发现它的master下线后，会对外广播failover信息，然后开始竞选master，当某个slave节点拥有半数以上的投票结果时，这个slave节点就会成为新的master。

选举流程：

1. slave发现master的状态变成fail
2. slave会对外广播failover信息，然后集群的选举周期+1
3. 其它节点接收到广播后，只有master才会响应，并且返回ack
4. 当该slave节点拥有半数以上的ack时，就成为新的master

### 集群节点的通信

redis cluster节点间采取gossip协议进行通信。

维护集群的元数据(集群节点信息，主从角色，节点数量，各节点共享的数据等)有两种方式：集中式和gossip

1. 集中式：

    优点在于元数据的更新和读取，时效性非常好，一旦元数据出现变更立即就会更新到集中式的存储中，其他节点读取的时候立即就可以立即感知到；不足在于所有的元数据的更新压力全部集中在一个地方，可能导致元数据的存储压力。 很多中间件都会借助zookeeper集中式存储元数据。

2. gossip：

    gossip协议包含多种消息，包括ping，pong，meet，fail等等。
    meet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信；
    ping：每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据(类似自己感知到的集群节点增加和移除，hash slot信息等)；
    pong: 对ping和meet消息的返回，包含自己的状态和其他信息，也可以用于信息广播和更新；
    fail: 某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了。

    gossip协议的优点在于元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力；缺点在于元数据更新有延时可能导致集群的一些操作会有一些滞后。

### 集群模式的脑裂问题

如果集群发生网络分区，导致一个从节点变成主节点提供服务，而旧的主节点也在提供服务，最终当网络恢复时两个节点的其中一个就只能作废，导致数据丢失。因此，Redis提供了一种限制主节点工作的条件，那就是它所拥有的从节点的数量。只有拥有指定数量从节点的主节点才可以提供服务。这样当发生分区时，新旧主节点中的一个会因为从节点数量不够而无法提供服务。



### 为什么Redis集群不使用一致性hash？

1. 数据迁移范围：扩缩容的时候，一致性哈希只会影响相关节点前后的数据迁移；而 redis cluster 则是全员参与，尽可能达到数据均分。redis cluster 集群数据就更加均分，也就是 数据倾斜 的几率更小。
2. 哈希槽的方式可以更便捷的新增/删除节点。



## Redis 内存碎片问题

分为内部碎片和外部碎片。

内部碎片：jemalloc分配机制导致。jemalloc是redis的默认内存分配器，其分配策略不是完全按照操作系统的按需分配来进行的，而是按照2^n次方的方式来分配，比如8字节，16字节，32字节、2KB，4KB，8KB等，固定大小。

外部碎片：redis每个键值的大小都不一致，频繁的修改操作可能会导致当有内存释放后有可能太小最终无法被马上使用。

Redis 内存碎片率的计算公式：`mem_fragmentation_ratio` （内存碎片率）= `used_memory_rss` (操作系统实际分配给 Redis 的物理内存空间大小)/ `used_memory`(Redis 内存分配器为了存储数据实际申请使用的内存空间大小)。通常情况下，我们认为 `mem_fragmentation_ratio > 1.5` 的话才需要清理内存碎片。

内存碎片的清理：Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。**核心思想就是对内存进行搬家合并，让空闲的内存合并到一起，形成大块可以使用的连续空间**。可以通过参数调节自动内存整理触发的时机，例如内存碎片占用的空间大小或者内存碎片率。为了不影响性能，也可以通过参数调节清理内存碎片占用CPU时间的比例。



## Redis 常见阻塞原因

### 1.高复杂度的命令

例如：

`KEYS *`：会返回所有符合规则的 key。

`HGETALL`：会返回一个 Hash 中所有的键值对。

`LRANGE`：会返回 List 中指定范围内的元素。

`SMEMBERS`：返回 Set 中的所有元素。

`SINTER`/`SUNION`/`SDIFF`：计算多个 Set 的交集/并集/差集。

### 2.持久化阻塞

AOF日志的刷盘策略有3种，always，everysec和no，对主线程的阻塞程度依次降低。

AOF重写的3步(创建子进程重写AOF文件、向新AOF文件追加AOF重写缓冲区、覆盖旧AOF文件)中，第2步由主线程完成且较为耗时。

RDB快照有两种生成方式，save和bgsave，前者会阻塞主线程，后者是使用后台线程完成快照。

### 3.大Key阻塞

大 key 造成的阻塞问题如下：

- 客户端超时阻塞：由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
- 引发网络阻塞：每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
- 阻塞工作线程：如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。

### 4.集群扩容

Redis 集群可以进行节点的动态扩容缩容，这一过程目前还处于半自动状态，需要人工介入。

在扩缩容的时候，需要进行数据迁移。而 Redis 为了保证迁移的一致性，迁移所有操作都是同步操作。

执行迁移时，两端的 Redis 均会进入时长不等的阻塞状态，对于小 Key，该时间可以忽略不计，但如果一旦 Key 的内存使用过大，严重的时候会触发集群内的故障转移，造成不必要的切换。

### 5.内存交换

Swap 对于 Redis 来说是非常致命的，Redis 保证高性能的一个重要前提是所有的数据在内存中。如果操作系统把 Redis 使用的部分内存换出硬盘，由于内存与硬盘的读写速度差几个数量级，会导致发生交换后的 Redis 性能急剧下降。

预防内存交换的方法：

- 保证机器充足的可用内存
- 确保所有 Redis 实例设置最大可用内存(maxmemory)，防止极端情况 Redis 内存不可控的增长
- 降低系统使用 swap 优先级，如`echo 10 > /proc/sys/vm/swappiness`

### 6.CPU竞争

Redis 是典型的 CPU 密集型应用，不建议和其他多核 CPU 密集型服务部署在一起。当其他进程过度消耗 CPU 时，将严重影响 Redis 的吞吐量。

### 7.网络问题

连接拒绝、网络延迟，网卡软中断等网络问题也可能会导致 Redis 阻塞。





 



## 什么是Spring

Spring 是一款开源的轻量级 Java 开发框架，旨在提高开发人员的开发效率以及系统的可维护性。

通常我们说的 Spring框架 指的是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发，比如说 Spring 支持 IoC控制反转 和 AOP面向切面编程；可以很方便地集成第三方组件，例如整合MyBatis方便地对数据库进行操作，SpringAMQP整合RabbitMQ可以方便地实现消息队列，整合Redis可以方便的实现缓存，SpringCloud整合Eureka、Feign、Ribbon、Hystrix、Gateway等组件方便的实现微服务等等；对单元测试支持比较好；支持 RESTful Java 应用程序的开发等。



## 谈谈你对IoC控制反转的理解

IoC（Inversion of Control:控制反转） 是一种设计思想，就是将程序中手动创建对象的控制权交给外部环境来管理，由外部环境来处理对象直接的依赖关系，自动注入成员对象。在Spring框架中有专门负责就是IoC容器的模块。在Spring时代通常使用xml文件来配置依赖关系的，在SpringBoot中则通常使用注解来配置。



## 什么是Spring Bean？

简单来说，Bean 代指的就是那些被 IoC 容器所管理的对象。

我们需要告诉 IoC 容器帮助我们管理哪些对象，这个是通过配置元数据来定义的。配置元数据可以是 XML 文件、注解或者 Java 配置类。



## 将一个类声明为 Bean 的注解有哪些?

- `@Component`：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用`@Component` 注解标注。
- `@Repository` : 对应持久层即 Dao 层，主要用于数据库相关操作。
- `@Service` : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。
- `@Controller` : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 `Service` 层返回数据给前端页面。



## @Component 和 @Bean 的区别是什么？

- `@Component` 注解作用于类，而`@Bean`注解作用于方法。
- `@Component`通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中。`@Bean` 注解通常是我们在标有该注解的方法中定义产生这个 bean,`@Bean`告诉了 Spring 这个方法的返回值是某个类的实例，需交由IoC容器管理。
- `@Bean` 注解比 `@Component` 注解的自定义性更强，而且很多地方我们只能通过 `@Bean` 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 `Spring`容器时，则只能通过 `@Bean`来实现。



## @Autowired 和 @Resource 的区别是什么？

`Autowired` 属于 Spring 内置的注解，默认的注入方式为`byType`（根据类型进行匹配），也就是说会优先根据接口类型去匹配并注入 Bean （接口的实现类）。

**这会有什么问题呢？** 当一个接口存在多个实现类的话，`byType`这种方式就无法正确注入对象了，因为这个时候 Spring 会同时找到多个满足条件的选择，默认情况下它自己不知道选择哪一个。这种情况下，注入方式会变为 `byName`（根据名称进行匹配），这个名称通常就是类名（首字母小写）。通过 `@Qualifier` 注解可以显式指定名称而不是依赖变量的名称。

`@Resource`属于 JDK 提供的注解，默认注入方式为 `byName`。如果无法通过名称匹配到对应的 Bean 的话，注入方式会变为`byType`。`@Resource` 有两个比较重要且日常开发常用的属性：`name`（名称）、`type`（类型）。如果仅指定 `name` 属性则注入方式为`byName`，如果仅指定`type`属性则注入方式为`byType`，如果同时指定`name` 和`type`属性（不建议这么做）则注入方式为`byType`+`byName`。

简单总结一下：

- `@Autowired` 是 Spring 提供的注解，`@Resource` 是 JDK 提供的注解。
- `Autowired` 默认的注入方式为`byType`（根据类型进行匹配），`@Resource`默认注入方式为 `byName`（根据名称进行匹配）。
- 当一个接口存在多个实现类的情况下，`@Autowired` 和`@Resource`都需要通过名称才能正确匹配到对应的 Bean。`Autowired` 可以通过 `@Qualifier` 注解来显式指定名称，`@Resource`可以通过 `name` 属性来显式指定名称。
- `@Autowired` 支持在构造函数、方法、字段和参数上使用。`@Resource` 主要用于字段和方法上的注入，不支持在构造函数或参数上使用。



## Bean的作用域有哪些？

Spring 中 Bean 的作用域通常有下面几种：

- **singleton** : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。
- **prototype** : 每次获取都会创建一个新的 bean 实例。也就是说，连续 `getBean()` 两次，得到的是不同的 Bean 实例。
- **request** （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。
- **session** （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。
- **application/global-session** （仅 Web 应用可用）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。
- **websocket** （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。

在普通的Spring项目中，只有前两种作用域，后四种状态的作用域是SpringMVC中使用的。

除此之外，singleton（单例作用域）和application（全局作用域）看似都是差不多的，那么它们到底有什么区别呢？

singleton是Spring Core的作用域；application是Spring Web中的作用域。singleton作用于IoC容器，而application作用于Servlet容器。




**如何配置 bean 的作用域呢？**

1. xml方式，scope属性
2. 注解方式 @scope



## Bean是线程安全的吗？

Spring 框架中的 Bean 是否线程安全，取决于其作用域和状态。

我们这里以最常用的两种作用域 prototype 和 singleton 为例介绍。几乎所有场景的 Bean 作用域都是使用默认的 singleton ，重点关注 singleton 作用域即可。

prototype 作用域下，每次获取都会创建一个新的 bean 实例，不存在资源竞争问题，所以不存在线程安全问题。

singleton 作用域下，IoC 容器中只有唯一的 bean 实例，可能会存在资源竞争问题（取决于 Bean 是否有状态）。如果这个 bean 是有状态的话，那就存在线程安全问题（有状态 Bean 是指包含可变的成员变量的对象）。

不过，大部分 Bean 实际都是无状态（没有定义可变的成员变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的。

对于有状态单例 Bean 的线程安全问题，常见的有两种解决办法：

1. 在 Bean 中尽量避免定义可变的成员变量。
2. 在类中定义一个 `ThreadLocal` 成员变量，将需要的可变成员变量保存在 `ThreadLocal` 中（推荐的一种方式）。



## 谈谈你对AOP的理解

AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。AOP可以在不改变源代码的基础上对代码功能进行增强。

Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 **JDK Proxy**，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 **Cglib** 生成一个被代理对象的子类来作为代理。

AOP 切面编程涉及到的一些专业术语：

|       术语        | 含义                                                         |
| :---------------: | :----------------------------------------------------------- |
|   目标(Target)    | 被通知的对象                                                 |
|    代理(Proxy)    | 向目标对象应用通知之后创建的代理对象                         |
| 连接点(JoinPoint) | 目标对象的所属类中，定义的所有方法均为连接点                 |
| 切入点(Pointcut)  | 被切面拦截 / 增强的连接点（切入点一定是连接点，连接点不一定是切入点） |
|   通知(Advice)    | 增强的逻辑 / 代码，也即拦截到目标对象的连接点之后要做的事情  |
|   切面(Aspect)    | 切入点(Pointcut)+通知(Advice)                                |
|   Weaving(织入)   | 将通知应用到目标对象，进而生成代理对象的过程动作             |



## Spring AOP 和 AspectJ AOP 有什么区别？

**Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。** Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。

Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，

如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。





## AspectJ 定义的通知类型有哪些？

- **Before**（前置通知）：目标对象的方法调用之前触发
- **After** （后置通知）：目标对象的方法调用之后触发
- **AfterReturning**（返回通知）：目标对象的方法调用完成，在返回结果值之后触发
- **AfterThrowing**（异常通知）：目标对象的方法运行中抛出 / 触发异常后触发。AfterReturning 和 AfterThrowing 两者互斥。如果方法调用成功无异常，则会有返回值；如果方法抛出了异常，则不会有返回值。
- **Around** （环绕通知）：编程式控制目标对象的方法调用。环绕通知是所有通知类型中可操作范围最大的一种，因为它可以直接拿到目标对象，以及要执行的方法，所以环绕通知可以任意的在目标对象的方法调用前后搞事，甚至不调用目标对象的方法



## 多个切面的执行顺序如何控制？

1. 通常使用`@Order` 注解直接定义切面顺序

2. 实现`Ordered` 接口重写 `getOrder` 方法。




## Spring 创建对象的时机

### 单例管理的对象 scope="singleton"

1. 默认情况下，Bean的作用域默认为单例类型。spring在读取xml文件的时候,就会创建对象。
2. 在创建的对象的时候(先调用构造器),会去调用init-method=".."属性值中所指定的方法.
3. 对象在被销毁的时候,会调用destroy-method="..."属性值中所指定的方法.(例如调用container.destroy()方法的时候)
4. lazy-init="true",可以让这个对象在第一次被访问的时候创建

### 非单例管理的对象 scope="prototype"

1. spring读取xml文件的时候,不会创建对象.
2. 在每一次访问这个对象的时候,spring容器都会创建这个对象,并且调用init-method=".."属性值中所指定的方法.
3. 对象销毁的时候,spring容器不会帮我们调用任何方法。因为是非单例,这个类型的对象有很多个,spring容器一旦把这个对象交给你之后,就不再管理这个对象了。





## Spring 创建对象(注入)的方式

### 1. 构造方法实例化

bean标签的class属性为实例类的全限定名。

有3种依赖注入方式。

+ Setter注入。使用property标签。

+ 构造器注入。
    + 对于无参数的(默认使用的构造器方法)，不能用构造器注入，只能用setter方法。
    + 对于有参数的，使用 constructor-arg 标签注入。
+ 自动装配。使用autowire标签，只能注入对象引用。



### 2. 静态工厂实例化

bean标签的class属性为工厂名，factory-method属性为工厂获取实例的静态方法。

两种注入方式：

+ Setter注入。使用property标签。另外注意，此时我们不光要在实现类中提供setter，还需要在工厂返回的接口类型中声明对应的setter方法。
+ 构造器注入。对于静态工厂实例化的对象，同样可以指定构造器参数，使用 constructor-arg 标签提供参数，此时，这些实参将被传递到factory-method的形参。然后，factory-method 使用这几个参数来调用实例类的构造器。
+ 自动装配。autowire标签，只能注入对象引用。



### 3.实例工厂实例化

bean标签的factory-bean属性是工厂类的bean标签的id，factory-method是获取实例的非静态方法。

两种注入方式：

+ Setter注入，同静态工厂。
+ 构造器注入，同静态工厂。
+ 自动装配。autowire标签，只能注入对象引用。



### 4.FactoryBean 实例化

这是第3种实例工厂实例化的变形。

实例工厂类实现 FactoryBean\<T\> 接口。

接口中的方法：

+ getObject ：代替原始实例工厂的创建对象的方法。这里getObject方法没有参数。初始化工作可以用Java代码在方法中实现。
+ getObjectType：返回范型T的class对象。
+ isSingleton()：返回是否使用单例模式。

**疑惑：使用该方法是不是就不能使用setter、构造器和自动装配进行注入了？**





## Spring整合Mybatis(配置文件版本)

要在Spring中整合Mybatis，首先来看使用配置文件方式：

使用配置文件又可以根据是否使用Mapper接口代理分为两类：

### 1. 不使用Mapper代理

在原始的Mybatis开发中，不使用Mapper代理的流程是：

1. 创建SqlSessionFactory。这一步包括配置enviroment等和配置mapper文件。
2. 创建SqlSession。
3. 在SqlSession上使用Mapper的namespace+id调用对应的SQL语句。

因此，我们只需要将SqlSession交由IoC容器管理，然后将SqlSession作为DAO注入service即可，但创建SqlSession需要SqlSessionFactory，我们将它也交给IoC容器。

SqlSessionFactory可以用org.mybatis.spring.SqlSessionFactoryBean创建。它需要注入一个 DataSource。此外，需要使用 mapperLocations 属性来配置mapper文件的位置。

```xml
<bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">
    <property name="dataSource" ref="dataSource" />
    <property name="mapperLocations" value="classpath*:com/itheima/dao/AccountDao.xml" />
</bean>
```

SqlSession 可以用 org.mybatis.spring.SqlSessionTemplate 来创建。SqlSessionTemplate 是 MyBatis-Spring 的核心，是 SqlSession 的一个实现类。在创建时，需要使用构造器注入SqlSessionFactory。

```xml
<bean id="sqlSession" class="org.mybatis.spring.SqlSessionTemplate">
    <constructor-arg name="sqlSessionFactory" ref="sqlSessionFactory"/>
</bean>
```

现在，可以把这个sqlSession注入任意一个ServiceImpl(可以使用类型自动装配)，然后在ServiceImpl中调用sqlSession.selectOne(namespace+id)等方法来执行SQL。



### 2. 使用Mapper代理

如果使用Mapper代理，就不需要使用SqlSession来完成SQL语句了，这样我们的Service就可以使用自己定义的DAO。这个DAO就是我们的Mapper代理接口。

此时我们需要将代理类交给IoC容器管理，然后将代理类注入给service即可。注册代理类有3种方式：

#### 2.1 使用 MapperFactoryBean 注册

使用 MapperFactoryBean 注册一个Mapper代理类，需要提供代理接口全限定名，以及创建它们的SqlSessionFactory。

注意，这里代理接口的路径由专门注册它的MapperFactoryBean来指定，所以SqlSessionFactoryBean就只需要配置数据源。另外，如果代理接口中有方法不是通过注解实现，而是通过xml配置文件实现的，那么只要配置文件和代理接口在同一目录下，也无需指定。但如果配置文件和代理接口不在同一目录下， 仍需要在SqlSessionFactoryBean中指定mapperLocations。

```xml
<bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">
    <property name="dataSource" ref="dataSource" />
</bean>

<bean id="accountDao" class="org.mybatis.spring.mapper.MapperFactoryBean">
    <property name="mapperInterface" value="com.itheima.dao.AccountDao" />
    <property name="sqlSessionFactory" ref="sqlSessionFactory" />
</bean>
```

然后，这个注册的代理类将具有mapperInterface指定的类型，从而可以作为DAO自动装配到某个service中。

注意，这种方式的特点是，每次只能使用一个MapperFactoryBean注册一个指定的代理类。

使用 MapperFactoryBean 注册只能逐个进行，这太麻烦了，下面的2种方式可以批量注册。



#### 2.2 使用 \<mybatis:scan\> 注册

`<mybatis:scan/>` 标签会发现映射器，它发现映射器的方法与 Spring 内建的 `<context:component-scan/>` 发现 bean 的方法非常类似。 在使用这个标签时，需要加载对应的名称空间。

可以使用这个标签的`base-package` 属性设置映射器接口文件的基础包。通过使用逗号或分号分隔，可以设置多个包，并且会在所指定的包中递归搜索映射器。

注意，虽然这个标签没有显式要求配置SqlSessionFactory，但创建它还是不可缺少的。

```xml
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:mybatis="http://mybatis.org/schema/mybatis-spring"
       xsi:schemaLocation="
           http://www.springframework.org/schema/beans
           http://www.springframework.org/schema/beans/spring-beans.xsd
           http://mybatis.org/schema/mybatis-spring
           http://mybatis.org/schema/mybatis-spring.xsd">

    <bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">
        <property name="dataSource" ref="dataSource" />
    </bean>
  	<mybatis:scan base-package="com.itheima.dao" />

  	<!-- ... -->
</beans>
```

被发现的映射器会按照 Spring 对自动发现组件的默认命名策略进行命名。也就是说，如果没有使用注解显式指定名称，将会使用映射器的首字母小写非全限定类名作为名称。但如果发现映射器具有 `@Component` 或 JSR-330 标准中 `@Named` 注解，会使用注解中的名称作为名称。

本质上，发现器会为基础包下的每个接口创建一个 MapperFactoryBean 。



#### 2.3 使用 MapperScannerConfigurer 注册

使用它来注册时，同样只需要指定Mapper接口所在的包，它将对这个包中的所有接口注册代理类，注册后的名字与mybatis-scan相同。

```xml
<bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">
    <property name="dataSource" ref="dataSource" />
</bean>

<bean id="mapperScannerConfigurer" class="org.mybatis.spring.mapper.MapperScannerConfigurer">
    <property name="basePackage" value="com.itheima.dao" />
</bean>
```

>关于要不要在Mapper接口上加@Mapper注解的问题，取决于mapperScannerConfigurer有没有扫描的目标。
>
>在SSM项目中，MapperScannerConfigurer 的 basePackage 是不可缺少的属性，它会扫描这个包下的所有接口，所以它注册代理类的机制和Mapper注解无关。
>
>在SpringBoot项目中，由于有自动配置，所以容器中会被自动注册MapperScannerConfigurer，但是这种自动注册的情况并未指定Mapper接口所在的包，所以需要为Mapper接口加@Mapper注解以让MapperScannerConfigurer找到它们来解析（前提：Mapper接口所在的包在@ComponentScan扫描的范围内）



## 纯注解 Mybatis-Spring

需要注册的对象见配置文件Mybatis-Spring。

### 1.不使用Mapper代理

只需要在MybatisConfig配置类中注册SqlSessionFactory和SqlSession即可。

SqlSessionFactory可以通过SqlSessionFactoryBean的getObject获取。在获取之前，需要配置数据源和SQL映射文件。

```java
@Bean
public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception {
    SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
    sqlSessionFactoryBean.setDataSource(dataSource);
    sqlSessionFactoryBean.setMapperLocations(resolveMapperLocations());
    return sqlSessionFactoryBean.getObject();
}

public Resource[] resolveMapperLocations() throws IOException {
    ResourcePatternResolver resourceResolver = new PathMatchingResourcePatternResolver();
    List<String> mapperLocations = new ArrayList<>();
    mapperLocations.add("classpath*:com/itheima/dao/*.xml");
    List<Resource> resources = new ArrayList();
    for (String mapperLocation : mapperLocations) {
        Resource[] mappers = resourceResolver.getResources(mapperLocation);
        resources.addAll(Arrays.asList(mappers));
    }
    System.out.println(resources.size());
    return resources.toArray(new Resource[resources.size()]);
}
```

SqlSession可以通过直接new一个sqlSessionTemplate获得，构造器中需要注入SqlSessionFactory。

```java
@Bean
public SqlSession sqlSession(SqlSessionFactory sqlSessionFactory) {
    return new SqlSessionTemplate(sqlSessionFactory);
}
```



### 2.使用Mapper代理

此时我们需要将代理类交给IoC容器管理，然后将代理类注入给service即可。注册代理类有3种方式：

#### 2.1 使用 MapperFactoryBean 注册

这里有一个需要注意的问题。这里不能返回MapperFactoryBean.getObject后的结果了，只能返回MapperFactoryBean自身。不过没关系，由于FactoryBean这类Bean很特殊，当使用ctx.getBean获取它时，不会返回FactoryBean，而是返回它封装的泛型类型。

至于为什么不能返回getObject后的结果，猜测是因为这个结果是一个接口，而IoC中不能直接注册一个接口，因此必须先注册FactoryBean。

为了统一起见，这里SqlSessionFactoryBean也返回了自身。

```java
@Bean
public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource) throws Exception {
    SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
    sqlSessionFactoryBean.setDataSource(dataSource);
    return sqlSessionFactoryBean;
}

@Bean
public MapperFactoryBean<AccountDao> accountDao(SqlSessionFactory sqlSessionFactory) throws Exception {
    MapperFactoryBean<AccountDao> mapperFactoryBean = new MapperFactoryBean<>();
    mapperFactoryBean.setSqlSessionFactory(sqlSessionFactory);
    mapperFactoryBean.setMapperInterface(com.itheima.dao.AccountDao.class);
    return mapperFactoryBean;
}
```



#### 2.2 使用 @MapperScan 注册

@MapperScan 注解是 \<mybatis:scan\> 从配置文件变成纯注解的形式。

只需要在配置类上添加@MapperScan注解，在其中写上base-package即可。可以写在@Configuration类上，也可以写在单独的配置类上后Import。

```java
@MapperScan("com.itheima.dao")
public class MybatisConfig {
    @Bean
    public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource) throws Exception {
        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
        sqlSessionFactoryBean.setDataSource(dataSource);
        return sqlSessionFactoryBean;
    }
}
```



#### 2.3 使用 MapperScannerConfigurer 注册

可以直接new一个MapperScannerConfigurer对象，然后配置basePackage即可。

```java
@Bean
public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource) throws Exception {
    SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
    sqlSessionFactoryBean.setDataSource(dataSource);
    return sqlSessionFactoryBean;
}

@Bean
public MapperScannerConfigurer mapperScannerConfigurer(){
    MapperScannerConfigurer msc = new MapperScannerConfigurer();
    msc.setBasePackage("com.itheima.dao");
    return msc;
}
```



综上，spring整合mybatis可以分为两大类，使用配置文件和使用纯注解。二者又分别具有两种类型，即不使用Mapper代理类和使用Mapper代理类。对于不使用Mapper代理类，配置文件方式和纯注解都是要创建SqlSessionFactory和SqlSession。对于使用Mapper代理类，配置文件和纯注解都有3种方式：

+ 每个代理类创建一个MapperFactoryBean；
+ 使用mybatis:scan/MapperScan()批量创建MapperFactoryBean；
+ 使用MapperScannerConfigurer批量创建MapperFactoryBean。



## Spring配置文件和纯注解扫描Bean的区别

配置文件中使用 \<context:component-scan base-packet="..."\> 标签来配置扫描的基础包。

纯注解中使用 @ComponentScan("...") 注解来配置扫描的基础包。多个基础包则用列表包装起来。



## Spring配置文件和纯注解加载Properties的区别

配置文件中使用 \<context:property-placeholder location="..."\> 标签来加载properties文件，可以使用通配符。

纯注解中使用 @PropertySource("...") 注解来配置。不可以使用通配符。多个配置文件可以使用列表包装起来。



## Spring配置文件和纯注解的自动装配的区别

配置文件自动装配是在bean标签上加属性 autowire="byType/byName"。这种方法要求要装配的成员有setter方法。

纯注解自动装配是在值类型成员上添加注解@Value(...)，在引用类型成员上添加注解@Autowired。内部使用反射暴力填充，不需要有setter方法。默认使用按类型装配，如果IoC容器中有名字与成员变量相同的Bean，则按照名字装配。另外，可以增加@Qualifier("beanName")注解来强制装配指定名称的Bean。





## 什么是classpath，classpath: 和 classpath*: 的区别

**classpath意为类路径，是Java程序的一个环境变量，JVM需要加载类文件时在classpath所指定的目录下搜索。通常来说classpath是当前项目的顶级package目录，也可以包含一些自定义的jar包目录，用于导入一些第三方jar包。**

"classpath:"或者"classpath*:"都不是Java语言自带的东西，它只是Spring自定义的一种路径格式前缀而己，意思是以classpath作为根目录的指定位置。

首先需要说明的是，"classpath:"与"classpath:/"对于Spring来说是没有区别的，Spring框架在处理这个路径的时候，会将开头的"/"符号去掉，这点对于"classpath*:/" 也是一样。

在说明 "classpath:" 和 "classpath*:" 的区别之前，我们先将 classpath 中的类路径分个类。

我们知道，classpath 包含两类路径：

1. 项目中顶层Package的路径和其他自定义的路径。该路径的子目录中包括了class文件的基目录，如com、org等包，也可能包括了一些资源文件目录等。为方便起见，我们统一称为**扩展路径**。
2. 项目要使用的所有JAR包的路径。为方便起见，我们称为**JAR包路径**。

Spring在使用这两个前缀搜索资源时，可能会在它们的后面加通配符，下面进行分类讨论。

### 不包含通配符的路径

所谓不包含通配符的路径，指的是"classpath:"以及"classpath\*:"后面资源文件的路径（含文件名）不包含通配符"*"、"?"等。Spring在进一步处理路径时，首先会判断路径是否包含通配符，有和没有通配符的处理方式是完全不同的，这也是我们分开讨论的原因。

1. classpath: 
    + 既可以查找扩展路径下的资源，也可以查找JAR包路径下的资源。
    + 查找顺序是按照类路径定义的顺序逐个查找(并不一定先查找扩展路径再查找JAR包路径），并返回查找到的第一个资源。
    + 返回的Resource都是ClasspathResource。
    + 如果资源位于扩展路径中，从ClasspathResource中获取到的是BufferedlnputStream。如果位于JAR包路径中，获取到的则是JarURLInputStream。

2. classpath*:
    + 既可以查找扩展路径下的资源，也可以查找JAR包路径下的资源。
    + 返回所有匹配的资源，所以查找顺序无关紧要。
    + 返回的Resource都是URLResource。
    + 如果资源位于扩展路径中，从URLResource获取到的是BufferedlnputStream；如果位于JAR包路径中，获取到的则是JarURLInputstream。



### 包含通配符的路径

包含通配符的路径指的是"classpath:"以及"classpath\*:" 后面资源文件的路径（含文件名）包含通配符"\*", "?"等。这种情况比较复杂，对于classpath尤其如此。

Spring在查找包含通配符的路径时，首先会从路径中提取出一个不包含通配符的"根目录"，它是从根路径开始的、一个没有通配符的最长路径”。例如，"classpath:static/image/\*\*/icon.png"的根目录为"static/image"，而"classpath:\*\*/image/first/icon.png" 的根目录为""（ 后面我们称为空目录），另外"classpath:i\*on.png"的根目录也是空目录。

可以看到，包含通配符的路径，其提取出的根目录有两种情况，一种是空目录，一种是包含了有效路径的目录，"classpath:"在这两种不同的根目录下查找行为有所区别，而"classpath*:"保持了一致。

1. classpath:
    1. 当根目录是空目录时：
        + 只能在扩展路径下查找资源，无法在JAR包路径内查找。
        + 查找过程：step1.首先过滤掉类路径中的JAR包路径，剩下的扩展路径保持定义顺序不变；step2.按照类路径定义的顺序逐个查找扩展路径，如果在某个扩展目录下查找到匹配的资源文件，则将查找范围锁定在该扩展目录下，并返回该扩展目录下所有匹配的资源文件。
        + 返回的Resource都是 FileSystemResource，从中获取FilelnputStream。
        + 实际上，之所以无法从JAR包路径中查找，是因为ClassLoader的getResources方法在传入""时，只能返回扩展路径资源。
    2. 当根目录是有效目录时：
        + 既可以查找扩展路径下的资源，也可以查找JAR包路径下的资源。
        + 查找过程：step1.直接按照类路径定义的顺序逐个查找扩展目录或jar包，如果查找到包含"根目录"的某个类路径，则将查找范围锁定在此类路径下，并返回此类路径下所有匹配的资源文件，如果没有匹配的就返回空。
        + 如果资源位于扩展路径中，返回的Resource是FileSystemResource, 从中获取到FilelnputStream。如果资源位于jar包中返回的Resource是 ClasspathResource，从中获取到JarURLInputStream。
2. classpath*:
    + 既可以查找扩展路径下的资源，也可以查找JAR包路径下的资源。
    + 返回查找到的所有的匹配文件资源，因此可以不考虑查找顺序。
    + 如果资源位于扩展路径中，返回的Resource是FileSystemResource，从中获取到FilelnputStream。如果资源位于jar包中，返回的Resource是URLResource，从中获取到 JarURLInputStream。



总结如下：

+ "classpath*:"  总是能在类路径的扩展目录和jar包中查找，并且返回所有的匹配资源。
+ "classpath:"（不含通配符）：总是能按照类路径定义的顺序逐个查找，并返回第一个匹配的资源。
+ "classpath:"（含通配符）：首先判断根目录是否为空，来决定查找的类路径范围是否需要过滤掉JAR包路径。在处理后的类路径中按照定义的顺序逐一查找，直到查找出第一个匹配的资源文件，同时锁定该资源文件所在的类路径。之后查找并返回该锁定的类路径中所有匹配的资源文件。





## Spring被@Bean修饰的方法 的参数注入方法

@Bean注解修饰的方法的参数默认注入方式为Autowired，先根据类型匹配，若有多个该类型的Bean则根据名称进行匹配。

这里需要注意，@Bean修饰的方法返回的Bean的名称默认为方法名。

当形式参数的类型有多个Bean时，按名称进行匹配默认使用参数名作为匹配的Bean名称，如果有@Qualifier注解则使用指定的名称。

另外，对于普通方法，其参数可以显式加@Autowired注解来注入。



## Spring的AOP 实现原理

SpringAOP是基于动态代理实现的。Spring在创建Bean前，会先读取所有的切面类，之后在创建Bean时，会将类的方法与所有切面类中的切入点进行匹配。如果一个类的方法有和切入点匹配成功的，那么就创建这个目标类的代理类对象，然后加入IOC容器，如果没有匹配成功的方法，那么就创建这个类本身的对象。

>**这里SpringBoot的机制存疑。**
>
>注意，这与SpringBoot不同，SpringBoot的依赖注入使用的是动态代理技术，因此在实例化接口时，SpringBoot会自动为这个接口创建一个代理对象，也就是说Spring Boot 会为每个使用了 @Service、@Component 等注解的类创建一个代理对象。当我们在其他类中使用 @Autowired 注解注入某个接口的时候，实际上注入的是这个接口的代理对象，而不是直接的实现类。

创建代理类对象时采用的方法是动态代理。Spring对不同的对象采用不同的动态代理机制：

1. 对于实现了接口的类，默认使用JDK动态代理，也可以强制使用CGLIB动态代理。
2. 对于没有实现接口的类，必须使用CGLIB动态代理。

JDK动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。而CGLIB动态代理是利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成目标类的子类来进行实例化。

Spring的事务管理中，@Transactional注解是基于AOP实现的，因此加了该注解的类或方法相当于使用AOP进行了增强，于是Spring会通过生成他们的代理类来实现事务功能。



## Spring的事务管理

### Spring中提供了两种事务管理机制：

+ 编程式事务：是指在代码中手动的管理事务的提交、回滚等操作，代码侵入性比较强。（Spring提供了TransactionTemplate模板，利用该模板我们可以通过编程的方式实现事务管理，而无需关注资源获取、复用、释放、事务同步及异常处理等操作。相对于声明式事务来说，这种方式相对麻烦一些，但是好在更为灵活，我们可以将事务管理的范围控制的更为精确）
+ 声明式事务：基于AOP面向切面的，它将具体业务与事务处理部分解耦，代码侵入性很低。而声明式事务有两种方式实现，方式一是基于@Transactional注解实现，方式二是基于XML实现。（Spring事务管理的亮点在于声明式事务管理，它允许我们通过声明的方式，在IoC配置中指定事务的边界和事务属性，Spring会自动在指定的事务边界上应用事务属性。相对于编程式事务来说，这种方式十分的方便，只需要在需要做事务管理的方法上，增加@Transactional注解，以声明事务特征即可）

@Transactional 可以作用在接口、类、方法：

1. 作用于接口：不推荐这种使用方法，因为一旦标注在Interface上并且配置了Spring AOP 使用CGLib动态代理，那么Spring将通过创建子类对象来动态代理实现类，这样就无法解析到@Transactional注解，从而导致@Transactional注解失效。因此，只有使用JDK代理时，接口上的注解才会生效。
2. 作用于类：当把@Transactional 注解放在类上时，代表这个类所有公共（public）非静态（static）非final的方法都将启用事务功能，且都会被 Spring 的事务管理器进行管理。
3. 作用于方法：当把@Transactional配置在方法上，该方法被当成一个独立的事务，且被事务管理器管理。当类配置了@Transactional，方法也配置了@Transactional，此时方法的事务会覆盖类的事务配置信息。

### @Transactional注解的实现原理

在方法上使用 @Transactional 注解时，Spring 将会创建一个代理对象来包装该方法。该代理对象将在该方法执行之前和之后添加一些代码，以启动和提交/回滚事务。

代理对象的创建和配置是由 Spring 的事务管理器完成的。Spring 支持多种事务管理器，例如 JDBC 事务管理器、Hibernate 事务管理器和 JTA 事务管理器。这些事务管理器负责管理事务的生命周期，并确保事务的一致性和隔离性。

在执行带有 @Transactional 注解的方法时，代理对象将首先尝试获取一个数据库连接。如果该方法已经在另一个事务中执行，则代理对象将重用该连接。否则，代理对象将从事务管理器中获取一个新的连接。然后，代理对象将启动事务，并将该连接与该事务相关联。

一旦方法执行完成，代理对象将检查方法是否抛出了异常。如果没有异常，则代理对象将提交事务，并将连接释放回事务管理器。如果方法抛出异常，则代理对象将回滚事务，并将连接释放回事务管理器。

需要注意的是，@Transactional 的默认行为是将 RuntimeException 和 Error 视为需要回滚事务的异常。这意味着如果您的方法抛出这些异常之一，则事务将被回滚。如果您想将其他异常也视为需要回滚事务的异常，则可以通过在 @Transactional 注解中添加 rollbackFor 属性来指定。



### @Transactional注解的失效场景：

### 1. @Transactional 应用在 非public 或 static 或 final方法上

@Transactional注解修饰的方法必须是public修饰的，同样的@Transactional修饰类时，也只有类中使用pulbic修饰的方法才能成为事务。
须知：使用@Transactional修饰的方法，必须是public修饰、非static修饰、非final修饰的，一个不满足就会导致事务失效。

这是由于Spring的事务是通过AOP实现的，在AOP增强时只能增强public、非static、非final的方法，因此事务注解也只能作用在此类方法上。AOP只能增强public，非static，非final方法的原因是，AOP是基于动态代理实现的，而无论是JDK动态代理还是CGLIB动态代理，他们都只支持代理上述的方法。JDK动态代理只能代理接口实现类，它创建了一个实现目标接口的匿名类，重写了要代理的方法，所以它只支持能够被重写的方法。CGLIB是通过创建修改目标类的子节码，创建目标类的子类来重写方法，因此它也只能代理子类可以重写的方法。从原理上来讲，CGLIB可以通过反射来访问父类的私有方法，但它没有这么做，也许是为了不破坏类设计者的初衷吧。



### 2. propagation 属性设置错误

当我们将 propagation 属性的值设置为一下几种取值就会导致事务失效：

1. Propagation.NOT_SUPPORTED：以非事务的方式运行，如果当前存在事务，暂停当前的事务
2. Propagation.NEVER：以非事务的方式运行，如果当前存在事务，则抛出异常



### 3. rollbackFor 属性设置错误

使用spring的@Transactiona开启事务,默认Error和RuntimeException及其子类才会回滚。如果在事务中抛出其他类型的异常，但却期望 Spring 能够回滚事务，就需要指定 rollbackFor属性；若在目标方法中抛出的异常是 rollbackFor 指定的异常的子类，事务同样会回滚。





### 4. 方法调用导致 @Transactional 失效

同一个类中，A方法是事务性方法，但是B方法是非事务性方法，如果使用B方法直接调用A，此时A方法的事务会失效。

这里的原因是，要使用经过AOP增强的A方法，就必须使用代理对象调用经过重写的A方法，但是如果直接从B方法中调用，那么调用的是未经过增强的A方法，因此不会有事务功能。解决办法是通过 AopContext.currentProxy() 这个API获取当前类的代理对象，在代理对象上调用A方法即可。



### 5. 异常捕获导致 @Transactional 失效

当一个事务方法中抛出了异常，此时该异常通过 try...catch 进行了捕获，导致异常被处理，那么事务将不会回滚，那么该方法的事务注解 @Transactional 失效。



### 6. 数据库引擎不支持事务

Spring的事务本质还是得靠数据库引擎的支持，如果数据库引擎不支持事务，那么Spring就算使用事务也是白搭。常用的MySQL数据库默认使用支持事务的innodb引擎。一旦数据库引擎切换成不支持事务的myisam，那事务就从根本上失效了。



### 7. 未启用事务

想要 @Transactional 注解实现声明式事务，首先就需要开启事务，开启事务就三步：

1. 配置事务管理器
2. 开启事务的注解驱动
3. 使用@Transactional



### 8. 事务方法启动新线程进行异步操作

Spring 的事务是通过LocalThread来保证线程安全的，事务和当前线程绑定，此时开启新线程执行业务，这个新线程的业务就会事务失效，因为事务是基于动态代理的，要想有事务，需要被动态代理。这里提供一种解决方法，可以将新的业务单独封装成一个方法，然后改方法上添加一个@Transactional，或者将这个方法单独抽取到一个类中，将该类交给IOC容器进行管理，这样就能让新线程的业务具有事务了。











